{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='darkred'>Yelp Recommendation System</font> \n",
    "### Team 14: Hikarun Murase (hikarum) & Tweesha Joshi (tweeshaj)\n",
    "#### December 13, 2018\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='brightpink'>Table of Contents</font> \n",
    "1. [Problem Domain](#Problemdomain)\n",
    "2. [Data](#data)\n",
    "    1. [How to Download Data](#download)\n",
    "    2. [Review Data](#review)\n",
    "    3. [User Data](#user)\n",
    "    4. [Business (restaurant) Data](#business)\n",
    "    5. [Data Cleaning](#datacleaning)\n",
    "3. [Methodology](#method)\n",
    "4. [Machine Learning](#ML)\n",
    "    1. [User-based Recommender](#userbased)\n",
    "    2. [Item-based Recommender](#itembased)\n",
    "    3. [Content-based Recommender](#contentbased)\n",
    "6. [Performance Evaluation](#performance)\n",
    "5. [Contribution and Future Tasks](#cont)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='brightpink'>Problem Domain</font> <a name=\"Problemdomain\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The type of machine learning task we conducted is recommendation. We constructed a personalized recommendation system for Yelp users. More specifically, we created a model that shows, for each user, personalized ratings of the restaurants which the user has not visited, based on other users’ ratings data.  \n",
    "  \n",
    "With reference to the inequality, P(T, E+ΔE) > P(T,E), Task (T) of our domain is providing a personalized star rating of the restaurants for each user, based on features such as the similarity among different users or restaurants. Experience (E) for our domain is user rating data. More specifically, E, is the star ratings of restaurants which Yelp users have visited before. In terms of learning, we aimed to demonstrate that adding more user rating data improves the performance measure. Performance (P) for our domain is error rate of our model prediction (predicted personalized ratings) compared to actual ratings. In the course of making a recommendation based on the personalized ratings, we can obtain the predicted ratings of every restaurants for every user and compare the actual ratings and predicted ratings. Making use of this nature, we assessed our work by comparing these ratings and calculating the root mean square error (RMSE) and the mean absolute error (MAE) through splitting data into training and test sets or performing k-fold cross validation. In that sense, our task can be also be broadly categorized as prediction.  \n",
    "    \n",
    "Yelp is an Internet search and review service for various businesses, but predominantly restaurants, where users can provide star ratings and text reviews for restaurants they have visited. Potential users (restaurant customers) can make use of the overall ratings and reviews posted by other users when they choose restaurants to visit. However, as of now, Yelp does not offer personalized star ratings of restaurants, or recommendation services, to users like other online platforms such as Amazon or Netflix. According to Yao et al., “the current rating system only provides an average value without considering any personalized information of the individual user. Thus, the efficacy of the rating system is diminished severely.”  In that context, we believe that constructing a recommender system would be useful for Yelp and could contribute to increasing their business value. Additionally, we were specifically interested in performing a recommendation task since we recently learned this in class and wanted to apply our new skills to a real-world business problem.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='brightpink'>Data</font> <a name=\"data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the data which is available on Yelp Dataset Challenge website (https://www.yelp.com/dataset/challenge). The data available there contains several JSON files which include user rating data (review.json), user data (user.json), and restaurant data (business.json). \n",
    "  \n",
    "According to Yelp Dataset JSON documentation, review.json contains ”full review text data including the user_id that wrote the review and the business_id the review is written for.”  We initially planed to download review.json and prepare a data table as shown in the last cells of this section. In the course of our analysis, since we found it was useful to merge user and restaurant information into the table, we also used user.json and business.json. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='brightpink'>How to Download the Data</font> <a name=\"download\"></a>\n",
    "\n",
    "*These three JSON files (review.json, user.json, and business.json) are contained in the submission folder (Google Drive). Therefore, if you successfully download the JSON files from the submission folder, you can ignore the following direction. On the other hand, if you cannot download them from the folder, you will need to follow the direction below to download directly from Yelp's website.*  \n",
    "\n",
    "1. Access Yelp Dataset Challenge (https://www.yelp.com/dataset/challenge) and click \"Download Dataset\"\n",
    "2. Fill out your information and click \"Download\", then download the .tar file on the left.\n",
    "3. Unzip (using 7-Zip or other proper software) the downloaded .tar file and again unzip the uncompressed file\n",
    "4. There are several JSON files including review.json, business.json, and user.json in the unzipped folder  \n",
    "  \n",
    "\n",
    "  \n",
    "*If you cannnot download these JSON files smoothly, you can also load CSV files (which are contained in the submission files) in the follwing chunks.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import OrderedDict\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math  # for sqrt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "import similarity as sim\n",
    "import matrix_factorization_utilities as m\n",
    "# you need to copy similarity.py and matrix_factorization_utilities.py\n",
    "# into the folder where this .ipynb file exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To graders: you do not need to execute this chunk.\n",
    "# This chunk is necessary for us to display the following plots. \n",
    "# You will need to have an account of \"plotly\" to run the following codes for plotting.\n",
    "# Therefore, for plotting parts, you can just refer to the HTML version of the report. \n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='brightpink'>Review Data</font> <a name=\"review\"></a>\n",
    "The review data table contains approximately 6 million (5,996,996) rows and three columns (which means there are 6 million reviews in the original data). The field “user_id” represents Yelp users.  \n",
    "\n",
    "Before any analysis, we performed some exploratory data exploration on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Review data exploration\n",
    "# load JSON file and store it into a list\n",
    "# (this might take a few minutes)\n",
    "with open('yelp_academic_dataset_review.json',  encoding=\"utf8\") as f: \n",
    "    reviews = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'business_id': 'iCQpiavjjPzJ5_3gPD5Ebg',\n",
       " 'cool': 0,\n",
       " 'date': '2011-02-25',\n",
       " 'funny': 0,\n",
       " 'review_id': 'x7mDIiDB3jEiPGPHOmDzyw',\n",
       " 'stars': 2,\n",
       " 'text': \"The pizza was okay. Not the best I've had. I prefer Biaggio's on Flamingo / Fort Apache. The chef there can make a MUCH better NY style pizza. The pizzeria @ Cosmo was over priced for the quality and lack of personality in the food. Biaggio's is a much better pick if youre going for italian - family owned, home made recipes, people that actually CARE if you like their food. You dont get that at a pizzeria in a casino. I dont care what you say...\",\n",
       " 'useful': 0,\n",
       " 'user_id': 'msQe1u7Z_XuqjGoqhB0J5g'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a sample of review data\n",
    "reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5996996"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total # of reviews in the dataset\n",
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x7mDIiDB3jEiPGPHOmDzyw</td>\n",
       "      <td>msQe1u7Z_XuqjGoqhB0J5g</td>\n",
       "      <td>iCQpiavjjPzJ5_3gPD5Ebg</td>\n",
       "      <td>2</td>\n",
       "      <td>2011-02-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dDl8zu1vWPdKGihJrwQbpw</td>\n",
       "      <td>msQe1u7Z_XuqjGoqhB0J5g</td>\n",
       "      <td>pomGBqfbxcqPv14c3XH-ZQ</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-11-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LZp4UX5zK3e-c5ZGSeo3kA</td>\n",
       "      <td>msQe1u7Z_XuqjGoqhB0J5g</td>\n",
       "      <td>jtQARsP6P-LbkyjbO1qNGg</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-10-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Er4NBWCmCD4nM8_p1GRdow</td>\n",
       "      <td>msQe1u7Z_XuqjGoqhB0J5g</td>\n",
       "      <td>elqbBhBfElMNSrjFqW3now</td>\n",
       "      <td>2</td>\n",
       "      <td>2011-02-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jsDu6QEJHbwP2Blom1PLCA</td>\n",
       "      <td>msQe1u7Z_XuqjGoqhB0J5g</td>\n",
       "      <td>Ums3gaP2qM3W1XcA5r6SsQ</td>\n",
       "      <td>5</td>\n",
       "      <td>2014-09-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  x7mDIiDB3jEiPGPHOmDzyw  msQe1u7Z_XuqjGoqhB0J5g  iCQpiavjjPzJ5_3gPD5Ebg   \n",
       "1  dDl8zu1vWPdKGihJrwQbpw  msQe1u7Z_XuqjGoqhB0J5g  pomGBqfbxcqPv14c3XH-ZQ   \n",
       "2  LZp4UX5zK3e-c5ZGSeo3kA  msQe1u7Z_XuqjGoqhB0J5g  jtQARsP6P-LbkyjbO1qNGg   \n",
       "3  Er4NBWCmCD4nM8_p1GRdow  msQe1u7Z_XuqjGoqhB0J5g  elqbBhBfElMNSrjFqW3now   \n",
       "4  jsDu6QEJHbwP2Blom1PLCA  msQe1u7Z_XuqjGoqhB0J5g  Ums3gaP2qM3W1XcA5r6SsQ   \n",
       "\n",
       "   stars        date  \n",
       "0      2  2011-02-25  \n",
       "1      5  2012-11-13  \n",
       "2      1  2014-10-23  \n",
       "3      2  2011-02-25  \n",
       "4      5  2014-09-05  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert into Pandas Data Frame and drop unnecessary columns \n",
    "# (this might take more than 10 minutes)\n",
    "reviews_df = pd.DataFrame.from_dict(reviews)\n",
    "reviews_df = reviews_df[['review_id', 'user_id', 'business_id', 'stars', 'date']]\n",
    "reviews_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as a CSV file (we can use the csv file next time)\n",
    "reviews_df.to_csv('reviews_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hika1\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:518: FutureWarning:\n",
      "\n",
      "elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# when loading, use the following code:\n",
    "reviews_df = pd.read_csv(\"reviews_df.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aggregated the review data by \"stars\" (user ratings). As you can see, the number of star 5 ratings is the highest, followd by 4 star ratings. Stars in Yelp appear to be integers from 1 to 5. Shown below in the bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    2641880\n",
       "4    1335957\n",
       "1     858139\n",
       "3     673206\n",
       "2     487813\n",
       "0          1\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# descriptive statistics for 'stars' used to plot graph \n",
    "ratings = reviews_df['stars'].value_counts()\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of star ratings \n",
    "# To graders: you do not need to execute this chunk.\n",
    "# Please refer to the HTML version of the report. \n",
    "ratings_plot = go.Bar(x=ratings.keys(),\n",
    "                    y=ratings.values,\n",
    "                     marker=dict(color='rgba(222,45,38,0.5)'))\n",
    "\n",
    "data = [ratings_plot]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Distribution of Ratings',\n",
    "        xaxis = dict(title = 'Star Rating'),\n",
    "    yaxis = dict(title = 'Number of Ratings')\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also aggregated the review data by year to analyze any trends seen in Yelp ratings over the last 15 years. Every year from 2004, the number of reviews seem to be increasing gradually. This is considered proportional to Yelp's growth (as well as the Internet's growth). But in 2018, reviews seem to drop suddenly as shown in the bar chart below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2017    1194269\n",
       "2016    1066894\n",
       "2015     919171\n",
       "2014     681665\n",
       "2018     677379\n",
       "2013     470970\n",
       "2012     349939\n",
       "2011     286343\n",
       "2010     175177\n",
       "2009      94224\n",
       "2008      54390\n",
       "2007      20745\n",
       "2006       4953\n",
       "2005        864\n",
       "2004         13\n",
       "Name: date, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# descriptive statistics for 'date' (in year)\n",
    "# used to plot graph below\n",
    "review_date = reviews_df['date'].apply(lambda x: int(x[:4])).value_counts()\n",
    "review_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~tweeshaj/154.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To graders: You do not need to execute this chunk.\n",
    "# Please refer to the HTML version of the report. \n",
    "review_plot = go.Bar(x=review_date.keys(),\n",
    "                    y=review_date.values,\n",
    "                     marker=dict(color='rgba(0,128,128, 0.8)'))\n",
    "\n",
    "data = [review_plot]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Distribution of Ratings by Year',\n",
    "        xaxis = dict(title = 'Year'),\n",
    "    yaxis = dict(title = 'Number of Ratings')\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='brightpink'>User Data</font> <a name=\"user\"></a>\n",
    "Next, we explored the user data. The primary key of the data is 'user_id'. User names (presumably first names) are also given in this data. 'review_count' in this data indicates how many times each user has rated a restaurant. There are 1,518,169 unique users in the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. User data exploration\n",
    "# if you come across MemoryError, it is recommended to restart your machine\n",
    "with open('yelp_academic_dataset_user.json',  encoding=\"utf8\") as f:\n",
    "    users = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'average_stars': 2.0,\n",
       " 'compliment_cool': 0,\n",
       " 'compliment_cute': 0,\n",
       " 'compliment_funny': 0,\n",
       " 'compliment_hot': 0,\n",
       " 'compliment_list': 0,\n",
       " 'compliment_more': 0,\n",
       " 'compliment_note': 0,\n",
       " 'compliment_photos': 0,\n",
       " 'compliment_plain': 0,\n",
       " 'compliment_profile': 0,\n",
       " 'compliment_writer': 0,\n",
       " 'cool': 0,\n",
       " 'elite': 'None',\n",
       " 'fans': 0,\n",
       " 'friends': 'None',\n",
       " 'funny': 0,\n",
       " 'name': 'Susan',\n",
       " 'review_count': 1,\n",
       " 'useful': 0,\n",
       " 'user_id': 'lzlZwIpuSWXEnNS91wxjHw',\n",
       " 'yelping_since': '2015-09-28'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a sample of user data\n",
    "users[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1518169"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total # of users in the dataset\n",
    "len(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert into Pandas Data Frame\n",
    "users_df = pd.DataFrame.from_dict(users)\n",
    "users_df = users_df[['user_id', 'name', 'review_count', 'average_stars', 'yelping_since']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as a CSV file (we can use the csv file next time)\n",
    "users_df.to_csv('users_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hika1\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:518: FutureWarning:\n",
      "\n",
      "elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# when loading, use the following code:\n",
    "users_df = pd.read_csv(\"users_df.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>review_count</th>\n",
       "      <th>average_stars</th>\n",
       "      <th>yelping_since</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lzlZwIpuSWXEnNS91wxjHw</td>\n",
       "      <td>Susan</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2015-09-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XvLBr-9smbI0m_a7dXtB7w</td>\n",
       "      <td>Daipayan</td>\n",
       "      <td>2</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2015-09-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QPT4Ud4H5sJVr68yXhoWFw</td>\n",
       "      <td>Andy</td>\n",
       "      <td>1</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2016-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i5YitlHZpf0B3R0s_8NVuw</td>\n",
       "      <td>Jonathan</td>\n",
       "      <td>19</td>\n",
       "      <td>4.05</td>\n",
       "      <td>2014-08-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s4FoIXE_LSGviTHBe8dmcg</td>\n",
       "      <td>Shashank</td>\n",
       "      <td>3</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2017-06-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id      name  review_count  average_stars yelping_since\n",
       "0  lzlZwIpuSWXEnNS91wxjHw     Susan             1           2.00    2015-09-28\n",
       "1  XvLBr-9smbI0m_a7dXtB7w  Daipayan             2           5.00    2015-09-05\n",
       "2  QPT4Ud4H5sJVr68yXhoWFw      Andy             1           4.00    2016-07-21\n",
       "3  i5YitlHZpf0B3R0s_8NVuw  Jonathan            19           4.05    2014-08-04\n",
       "4  s4FoIXE_LSGviTHBe8dmcg  Shashank             3           3.00    2017-06-18"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following result and line graph below demonstrate the number of users who have rated N restaurants or more. Of more than 1.5 million Yelp users, approximately half of them have rated 5 or more restaurants. Users who have rated 1,000 restaurants or more are only 0.1% of the entire users dataset. In our analysis we decided to use the 1365 users who reviewed a 1000 ratings or more so provide a comprehensive recommendation for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N >= 1 1517743\n",
      "N >= 2 1233092\n",
      "N >= 5 793174\n",
      "N >= 10 522482\n",
      "N >= 30 221362\n",
      "N >= 100 68637\n",
      "N >= 500 6400\n",
      "N >= 1000 1365\n"
     ]
    }
   ],
   "source": [
    "# What portion of users who reviewed N times or more? (N=1,2,5,10,30,50,100)\n",
    "print ('N >= 1', len(users_df[users_df['review_count'] >= 1]))\n",
    "print ('N >= 2', len(users_df[users_df['review_count'] >= 2]))\n",
    "print ('N >= 5', len(users_df[users_df['review_count'] >= 5]))\n",
    "print ('N >= 10', len(users_df[users_df['review_count'] >= 10]))\n",
    "print ('N >= 30', len(users_df[users_df['review_count'] >= 30]))\n",
    "print ('N >= 100', len(users_df[users_df['review_count'] >= 100]))\n",
    "print ('N >= 500', len(users_df[users_df['review_count'] >= 500]))\n",
    "print ('N >= 1000', len(users_df[users_df['review_count'] >= 1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~tweeshaj/152.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To graders: You do not need to execute this chunk.\n",
    "# Please refer to the HTML version of the report. \n",
    "user_ratings_plot = go.Scatter(x = (1,5,10,30,100,500,1000),\n",
    "                               y=(len(users_df[users_df['review_count'] >= 1]),len(users_df[users_df['review_count'] >= 5]),\n",
    "                                len(users_df[users_df['review_count'] >= 10]), len(users_df[users_df['review_count'] >= 30]), \n",
    "                                len(users_df[users_df['review_count'] >= 100]), len(users_df[users_df['review_count'] >= 500]), \n",
    "                                len(users_df[users_df['review_count'] >= 1000])),\n",
    "                             text= ['>1 restaurant', '>5 restaurants', '>10 restaurants', '>30 restaurants',\n",
    "                                    '>100 restaurants', '>500 restaurants', '>1000 restaurants'],\n",
    "                             mode = 'lines+markers',\n",
    "                              marker=dict(color='rgba(0,0,255, 0.8)'))\n",
    "data = [user_ratings_plot]\n",
    "layout = go.Layout(\n",
    "    title='Number of Users who have Rated N Restaurants or More',\n",
    "    xaxis = dict(title = 'Number of Restaurants Rated'),\n",
    "    yaxis = dict(title = 'Number of Users')\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1365"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will choose only users who reviews 1,000 times or more.\n",
    "users_df2 = users_df[users_df['review_count'] >=1000]\n",
    "len(users_df2) # display the size (# of users who have reviewed 1000 times or more)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='brightpink'>Business (restaurant) Data</font> <a name=\"business\"></a>\n",
    "Finally, we explored business (restaurant) data. Similar to user data, restaurant names are provided in the data. We can identify a rough location of restaurants because their location information such as state is given. As far as we confirmed, it seems that the data contains restaurants across the United States and Canada. “business_id” plays a role as a primary key for restaurants. \"review_count\" represents the number of reviews which users have posted for each restaurant. There are 188,593 unique restaurants in the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Restaurant (business) data exploration\n",
    "with open('yelp_academic_dataset_business.json',  encoding=\"utf8\") as f:\n",
    "    businesses = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'address': '1314 44 Avenue NE',\n",
       " 'attributes': {'BikeParking': 'False',\n",
       "  'BusinessAcceptsCreditCards': 'True',\n",
       "  'BusinessParking': \"{'garage': False, 'street': True, 'validated': False, 'lot': False, 'valet': False}\",\n",
       "  'GoodForKids': 'True',\n",
       "  'HasTV': 'True',\n",
       "  'NoiseLevel': 'average',\n",
       "  'OutdoorSeating': 'False',\n",
       "  'RestaurantsAttire': 'casual',\n",
       "  'RestaurantsDelivery': 'False',\n",
       "  'RestaurantsGoodForGroups': 'True',\n",
       "  'RestaurantsPriceRange2': '2',\n",
       "  'RestaurantsReservations': 'True',\n",
       "  'RestaurantsTakeOut': 'True'},\n",
       " 'business_id': 'Apn5Q_b6Nz61Tq4XzPdf9A',\n",
       " 'categories': 'Tours, Breweries, Pizza, Restaurants, Food, Hotels & Travel',\n",
       " 'city': 'Calgary',\n",
       " 'hours': {'Friday': '11:0-21:0',\n",
       "  'Monday': '8:30-17:0',\n",
       "  'Saturday': '11:0-21:0',\n",
       "  'Thursday': '11:0-21:0',\n",
       "  'Tuesday': '11:0-21:0',\n",
       "  'Wednesday': '11:0-21:0'},\n",
       " 'is_open': 1,\n",
       " 'latitude': 51.0918130155,\n",
       " 'longitude': -114.031674872,\n",
       " 'name': 'Minhas Micro Brewery',\n",
       " 'neighborhood': '',\n",
       " 'postal_code': 'T2E 6L6',\n",
       " 'review_count': 24,\n",
       " 'stars': 4.0,\n",
       " 'state': 'AB'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a sample of business data\n",
    "businesses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188593"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total # of restaurants in the dataset\n",
    "len(businesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert into Pandas Data Frame\n",
    "businesses_df_original = pd.DataFrame.from_dict(businesses)\n",
    "businesses_df = businesses_df_original[['business_id', 'name', 'review_count', 'stars', 'state']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as a CSV file (we can use the csv file next time)\n",
    "businesses_df_original.to_csv('businesses_df_original.csv')\n",
    "businesses_df.to_csv('businesses_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when loading, use the following code:\n",
    "businesses_df_original = pd.read_csv(\"businesses_df_original.csv\", index_col=0)\n",
    "businesses_df = pd.read_csv(\"businesses_df.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>review_count</th>\n",
       "      <th>stars</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apn5Q_b6Nz61Tq4XzPdf9A</td>\n",
       "      <td>Minhas Micro Brewery</td>\n",
       "      <td>24</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AjEbIBw6ZFfln7ePHha9PA</td>\n",
       "      <td>CK'S BBQ &amp; Catering</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O8S5hYJ1SMc8fA4QBtVujA</td>\n",
       "      <td>La Bastringue</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>QC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bFzdJJ3wp3PZssNEsyU23g</td>\n",
       "      <td>Geico Insurance</td>\n",
       "      <td>8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8USyCYqpScwiNEb58Bt6CA</td>\n",
       "      <td>Action Engine</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                  name  review_count  stars state\n",
       "0  Apn5Q_b6Nz61Tq4XzPdf9A  Minhas Micro Brewery            24    4.0    AB\n",
       "1  AjEbIBw6ZFfln7ePHha9PA   CK'S BBQ & Catering             3    4.5    NV\n",
       "2  O8S5hYJ1SMc8fA4QBtVujA         La Bastringue             5    4.0    QC\n",
       "3  bFzdJJ3wp3PZssNEsyU23g       Geico Insurance             8    1.5    AZ\n",
       "4  8USyCYqpScwiNEb58Bt6CA         Action Engine             4    2.0    AB"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "businesses_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code indicates the number of restaurants which have been rated N times or more. More than a half of the restaurants have been reviewed by more than 10 unique users, and restaurants with more than 500 reviews are less than 1% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N >= 1 188593\n",
      "N >= 2 188593\n",
      "N >= 5 135578\n",
      "N >= 10 89041\n",
      "N >= 30 39652\n",
      "N >= 100 12058\n",
      "N >= 500 1099\n",
      "N >= 1000 309\n"
     ]
    }
   ],
   "source": [
    "# What portion of restaurants which have review counts of N or more? (N=1,2,5,10,30,50,100)\n",
    "print ('N >= 1', len(businesses_df[businesses_df['review_count'] >= 1]))\n",
    "print ('N >= 2', len(businesses_df[businesses_df['review_count'] >= 2]))\n",
    "print ('N >= 5', len(businesses_df[businesses_df['review_count'] >= 5]))\n",
    "print ('N >= 10', len(businesses_df[businesses_df['review_count'] >= 10]))\n",
    "print ('N >= 30', len(businesses_df[businesses_df['review_count'] >= 30]))\n",
    "print ('N >= 100', len(businesses_df[businesses_df['review_count'] >= 100]))\n",
    "print ('N >= 500', len(businesses_df[businesses_df['review_count'] >= 500]))\n",
    "print ('N >= 1000', len(businesses_df[businesses_df['review_count'] >= 1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~tweeshaj/150.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To graders: You do not need to execute this chunk.\n",
    "# Please refer to the HTML version of the report. \n",
    "rest_ratings_plot = go.Scatter(x = (1,5,10,30,100,500,1000),\n",
    "                               y=(len(businesses_df[businesses_df['review_count'] >= 1]),len(businesses_df[businesses_df['review_count'] >= 5]),\n",
    "                                len(businesses_df[businesses_df['review_count'] >= 10]), len(businesses_df[businesses_df['review_count'] >= 30]), \n",
    "                                len(businesses_df[businesses_df['review_count'] >= 100]), len(businesses_df[businesses_df['review_count'] >= 500]), \n",
    "                                len(businesses_df[businesses_df['review_count'] >= 1000])),\n",
    "                             text= ['>1 review', '>5 reviews', '>10 reviews', '>30 reviews',\n",
    "                                    '>100 reviews', '>500 reviews', '>1000 reviews'],\n",
    "                             mode = 'lines+markers',\n",
    "                              marker=dict(color='rgba(0,255,0, 0.8)'))\n",
    "data = [rest_ratings_plot]\n",
    "layout = go.Layout(\n",
    "    title='Number of Restaurants that are Reviewed N times or More',\n",
    "    xaxis = dict(title = 'Number of Reviews'),\n",
    "    yaxis = dict(title = 'Number of Restaurants')\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we aggregated restaurants by state. Most of the restaurants in the data are located in Arizona, Nevada, Ontario (Canada), North Carolina, Ohio, and Pennsylvania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AZ     56495\n",
       "NV     35688\n",
       "ON     32393\n",
       "NC     14359\n",
       "OH     13664\n",
       "PA     10966\n",
       "QC      8756\n",
       "AB      7670\n",
       "WI      5042\n",
       "IL      1937\n",
       "SC       770\n",
       "NYK      163\n",
       "NI       134\n",
       "IN       101\n",
       "OR        72\n",
       "BY        60\n",
       "ST        45\n",
       "CO        43\n",
       "C         34\n",
       "HE        32\n",
       "XGM       23\n",
       "NLK       23\n",
       "RP        19\n",
       "NY        19\n",
       "01        11\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of states among restaurants\n",
    "businesses_df['state'].value_counts().head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 States with more than 1000 restaurants on Yelp (We used the top 6 states is our analysis)\n",
    "# used to plot graph below\n",
    "bus_state = businesses_df['state'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~tweeshaj/156.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To graders: You do not need to execute this chunk.\n",
    "# Please refer to the HTML version of the report. \n",
    "bus_state_plot = go.Bar(x=bus_state.keys(),\n",
    "                    y=bus_state.values)\n",
    "\n",
    "data = [bus_state_plot]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Top 10 States with the Most Restaurants',\n",
    "    xaxis = dict(title = 'State'),\n",
    "    yaxis = dict(title = 'Number of Restaurants (on Yelp)')\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will choose restaurants which has 1,000 or more reviews and \n",
    "# in AZ, NV, ON (Canada), NC, OH, and PA (the top 6 states)\n",
    "businesses_df2 = businesses_df[(businesses_df['review_count']>=1000) & \n",
    "                               ((businesses_df['state']=='AZ') | \n",
    "                                (businesses_df['state']=='NV') |\n",
    "                                (businesses_df['state']=='ON') |\n",
    "                                (businesses_df['state']=='NC') |\n",
    "                                (businesses_df['state']=='OH') |\n",
    "                                (businesses_df['state']=='PA') )]\n",
    "businesses_df2.head(10)\n",
    "len(businesses_df2) # display the size (# of restaurants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='brightpink'>Data Join and Data Cleaning</font> <a name=\"datacleaning\"></a>\n",
    "As our project, we filtered the 6-million review data following the three criteria mentioned below:  \n",
    "1. Users who have reviewed for 1,000 or more restaurants\n",
    "2. Restaurants which have been reviewed by 1,000 or more users\n",
    "3. Restaurants which are located in Arizona, Nevada, Ontario, North Carolina, Ohio, or Pennsylvania. \n",
    "\n",
    "One of the reasons to do this is to avoid a memory error. We first tried to use the entire original data; however, we could not even merge and clean the data due to a memory error. To avoid this issue, it was necessary for us to reduce the size of the data to use.   \n",
    "  \n",
    "Another reason is to increase the portion of non-null values in a user-item matrix, which we will use to make a recommendation (prediction) for users. As we saw above, some users have rated only a few restaurants. Likewise, some restaurants have been rated by only a few users. Such data is unlikely to be used to make a recommendation because there are no similar users/restaurants in the data. Thus, it is efficient to remove such users/restaurants from the data to use.  \n",
    "  \n",
    "In the following chunk, we merged the review data with restaurant data and user data to achive it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "531882\n",
      "14711\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars_review</th>\n",
       "      <th>date</th>\n",
       "      <th>name_business</th>\n",
       "      <th>review_count_business</th>\n",
       "      <th>stars_business</th>\n",
       "      <th>state</th>\n",
       "      <th>name_user</th>\n",
       "      <th>review_count_user</th>\n",
       "      <th>average_stars</th>\n",
       "      <th>yelping_since</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MFILe8F1qzSK_22zQSukxw</td>\n",
       "      <td>LyrAjv8V6HWkceuTB4Xtkw</td>\n",
       "      <td>iCQpiavjjPzJ5_3gPD5Ebg</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-05-14</td>\n",
       "      <td>Secret Pizza</td>\n",
       "      <td>4078</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>Duke</td>\n",
       "      <td>1170</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2008-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WaCsltXdV1ag_FKY3tR7jQ</td>\n",
       "      <td>LyrAjv8V6HWkceuTB4Xtkw</td>\n",
       "      <td>f4x1YBxkLrZg652xt2KR5g</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-17</td>\n",
       "      <td>Hash House A Go Go</td>\n",
       "      <td>5382</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>Duke</td>\n",
       "      <td>1170</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2008-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uSxPoQQ7xQj2CH6Oyxu2Zg</td>\n",
       "      <td>LyrAjv8V6HWkceuTB4Xtkw</td>\n",
       "      <td>DkYS3arLOhA8si5uUEmHOw</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-04-27</td>\n",
       "      <td>Earl of Sandwich</td>\n",
       "      <td>4981</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NV</td>\n",
       "      <td>Duke</td>\n",
       "      <td>1170</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2008-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B_qmwryaFoXNHUSqtN3pKA</td>\n",
       "      <td>LyrAjv8V6HWkceuTB4Xtkw</td>\n",
       "      <td>K7lWdNUhCbcnEvI0NhGewg</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-07-13</td>\n",
       "      <td>Wicked Spoon</td>\n",
       "      <td>6446</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NV</td>\n",
       "      <td>Duke</td>\n",
       "      <td>1170</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2008-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zodfk1QxukafgD3-jIGbsQ</td>\n",
       "      <td>LyrAjv8V6HWkceuTB4Xtkw</td>\n",
       "      <td>NvKNe9DnQavC9GstglcBJQ</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-07-30</td>\n",
       "      <td>Grand Lux Cafe</td>\n",
       "      <td>2670</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>Duke</td>\n",
       "      <td>1170</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2008-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pc9hrm9LVKPCe41j-CcdvA</td>\n",
       "      <td>LyrAjv8V6HWkceuTB4Xtkw</td>\n",
       "      <td>MpmFFw0GE_2iRFPdsRpJbA</td>\n",
       "      <td>5</td>\n",
       "      <td>2011-07-12</td>\n",
       "      <td>XS Nightclub</td>\n",
       "      <td>2915</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>Duke</td>\n",
       "      <td>1170</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2008-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mispDRX2DZTZuGGOznkNIg</td>\n",
       "      <td>LyrAjv8V6HWkceuTB4Xtkw</td>\n",
       "      <td>ujHiaprwCQ5ewziu0Vi9rw</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-05-20</td>\n",
       "      <td>The Buffet at Bellagio</td>\n",
       "      <td>4091</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NV</td>\n",
       "      <td>Duke</td>\n",
       "      <td>1170</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2008-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cUo2TvljZu3eo0Sbu0vNXQ</td>\n",
       "      <td>LyrAjv8V6HWkceuTB4Xtkw</td>\n",
       "      <td>rcaPajgKOJC2vo_l3xa42A</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-08-04</td>\n",
       "      <td>Bouchon at the Venezia Tower</td>\n",
       "      <td>3743</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>Duke</td>\n",
       "      <td>1170</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2008-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HddoeXBzmLBvrNpljFZ8Ag</td>\n",
       "      <td>LyrAjv8V6HWkceuTB4Xtkw</td>\n",
       "      <td>LNGBEEelQx4zbfWnlc66cw</td>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-27</td>\n",
       "      <td>Studio B Buffet</td>\n",
       "      <td>2155</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>Duke</td>\n",
       "      <td>1170</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2008-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9cykx5-k4UiEAid_3LhF4g</td>\n",
       "      <td>LyrAjv8V6HWkceuTB4Xtkw</td>\n",
       "      <td>7fxebHYUwIF6CakxSr70iQ</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-08-27</td>\n",
       "      <td>Carnevino</td>\n",
       "      <td>1347</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NV</td>\n",
       "      <td>Duke</td>\n",
       "      <td>1170</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2008-08-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  MFILe8F1qzSK_22zQSukxw  LyrAjv8V6HWkceuTB4Xtkw  iCQpiavjjPzJ5_3gPD5Ebg   \n",
       "1  WaCsltXdV1ag_FKY3tR7jQ  LyrAjv8V6HWkceuTB4Xtkw  f4x1YBxkLrZg652xt2KR5g   \n",
       "2  uSxPoQQ7xQj2CH6Oyxu2Zg  LyrAjv8V6HWkceuTB4Xtkw  DkYS3arLOhA8si5uUEmHOw   \n",
       "3  B_qmwryaFoXNHUSqtN3pKA  LyrAjv8V6HWkceuTB4Xtkw  K7lWdNUhCbcnEvI0NhGewg   \n",
       "4  Zodfk1QxukafgD3-jIGbsQ  LyrAjv8V6HWkceuTB4Xtkw  NvKNe9DnQavC9GstglcBJQ   \n",
       "5  pc9hrm9LVKPCe41j-CcdvA  LyrAjv8V6HWkceuTB4Xtkw  MpmFFw0GE_2iRFPdsRpJbA   \n",
       "6  mispDRX2DZTZuGGOznkNIg  LyrAjv8V6HWkceuTB4Xtkw  ujHiaprwCQ5ewziu0Vi9rw   \n",
       "7  cUo2TvljZu3eo0Sbu0vNXQ  LyrAjv8V6HWkceuTB4Xtkw  rcaPajgKOJC2vo_l3xa42A   \n",
       "8  HddoeXBzmLBvrNpljFZ8Ag  LyrAjv8V6HWkceuTB4Xtkw  LNGBEEelQx4zbfWnlc66cw   \n",
       "9  9cykx5-k4UiEAid_3LhF4g  LyrAjv8V6HWkceuTB4Xtkw  7fxebHYUwIF6CakxSr70iQ   \n",
       "\n",
       "   stars_review        date                 name_business  \\\n",
       "0             4  2012-05-14                  Secret Pizza   \n",
       "1             4  2011-01-17            Hash House A Go Go   \n",
       "2             4  2011-04-27              Earl of Sandwich   \n",
       "3             4  2011-07-13                  Wicked Spoon   \n",
       "4             3  2012-07-30                Grand Lux Cafe   \n",
       "5             5  2011-07-12                  XS Nightclub   \n",
       "6             3  2010-05-20        The Buffet at Bellagio   \n",
       "7             3  2016-08-04  Bouchon at the Venezia Tower   \n",
       "8             5  2011-09-27               Studio B Buffet   \n",
       "9             4  2010-08-27                     Carnevino   \n",
       "\n",
       "   review_count_business  stars_business state name_user  review_count_user  \\\n",
       "0                   4078             4.0    NV      Duke               1170   \n",
       "1                   5382             4.0    NV      Duke               1170   \n",
       "2                   4981             4.5    NV      Duke               1170   \n",
       "3                   6446             3.5    NV      Duke               1170   \n",
       "4                   2670             4.0    NV      Duke               1170   \n",
       "5                   2915             4.0    NV      Duke               1170   \n",
       "6                   4091             3.5    NV      Duke               1170   \n",
       "7                   3743             4.0    NV      Duke               1170   \n",
       "8                   2155             4.0    NV      Duke               1170   \n",
       "9                   1347             3.5    NV      Duke               1170   \n",
       "\n",
       "   average_stars yelping_since  \n",
       "0           3.76    2008-08-18  \n",
       "1           3.76    2008-08-18  \n",
       "2           3.76    2008-08-18  \n",
       "3           3.76    2008-08-18  \n",
       "4           3.76    2008-08-18  \n",
       "5           3.76    2008-08-18  \n",
       "6           3.76    2008-08-18  \n",
       "7           3.76    2008-08-18  \n",
       "8           3.76    2008-08-18  \n",
       "9           3.76    2008-08-18  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform the following inner joins:\n",
    "#    Review JOIN Restaurant_df2 USING (business_id)\n",
    "#           JOIN User_df2       USING (user_id)\n",
    "# The output contains reveiws within the entire period from 2004 to 2017\n",
    "# for restaurants which has 1,000 or more reviews in AZ, NV, ON (Canada), NC, OH, and PA\n",
    "# by users who have reviewed 1,000 times or more \n",
    "\n",
    "review_business = pd.merge(reviews_df, businesses_df2, on='business_id', how='inner', suffixes=('_review', '_business'))\n",
    "print(len(review_business))\n",
    "\n",
    "review_business_user = pd.merge(review_business, users_df2, on='user_id', how='inner', suffixes=('_business', '_user'))\n",
    "print(len(review_business_user))\n",
    "\n",
    "review_business_user.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table displays the first ten rows of the merged and cleaned data. To make a recommendation, we will use \"review_id\", \"user_id\", \"business_id\", and \"stars.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size is 14711\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>business_name</th>\n",
       "      <th>state</th>\n",
       "      <th>business_review_count</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MFILe8F1qzSK_22zQSukxw</td>\n",
       "      <td>LyrAjv8V6HWkceuTB4Xtkw</td>\n",
       "      <td>iCQpiavjjPzJ5_3gPD5Ebg</td>\n",
       "      <td>4</td>\n",
       "      <td>Secret Pizza</td>\n",
       "      <td>NV</td>\n",
       "      <td>4078</td>\n",
       "      <td>Duke</td>\n",
       "      <td>1170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WaCsltXdV1ag_FKY3tR7jQ</td>\n",
       "      <td>LyrAjv8V6HWkceuTB4Xtkw</td>\n",
       "      <td>f4x1YBxkLrZg652xt2KR5g</td>\n",
       "      <td>4</td>\n",
       "      <td>Hash House A Go Go</td>\n",
       "      <td>NV</td>\n",
       "      <td>5382</td>\n",
       "      <td>Duke</td>\n",
       "      <td>1170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uSxPoQQ7xQj2CH6Oyxu2Zg</td>\n",
       "      <td>LyrAjv8V6HWkceuTB4Xtkw</td>\n",
       "      <td>DkYS3arLOhA8si5uUEmHOw</td>\n",
       "      <td>4</td>\n",
       "      <td>Earl of Sandwich</td>\n",
       "      <td>NV</td>\n",
       "      <td>4981</td>\n",
       "      <td>Duke</td>\n",
       "      <td>1170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B_qmwryaFoXNHUSqtN3pKA</td>\n",
       "      <td>LyrAjv8V6HWkceuTB4Xtkw</td>\n",
       "      <td>K7lWdNUhCbcnEvI0NhGewg</td>\n",
       "      <td>4</td>\n",
       "      <td>Wicked Spoon</td>\n",
       "      <td>NV</td>\n",
       "      <td>6446</td>\n",
       "      <td>Duke</td>\n",
       "      <td>1170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zodfk1QxukafgD3-jIGbsQ</td>\n",
       "      <td>LyrAjv8V6HWkceuTB4Xtkw</td>\n",
       "      <td>NvKNe9DnQavC9GstglcBJQ</td>\n",
       "      <td>3</td>\n",
       "      <td>Grand Lux Cafe</td>\n",
       "      <td>NV</td>\n",
       "      <td>2670</td>\n",
       "      <td>Duke</td>\n",
       "      <td>1170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pc9hrm9LVKPCe41j-CcdvA</td>\n",
       "      <td>LyrAjv8V6HWkceuTB4Xtkw</td>\n",
       "      <td>MpmFFw0GE_2iRFPdsRpJbA</td>\n",
       "      <td>5</td>\n",
       "      <td>XS Nightclub</td>\n",
       "      <td>NV</td>\n",
       "      <td>2915</td>\n",
       "      <td>Duke</td>\n",
       "      <td>1170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mispDRX2DZTZuGGOznkNIg</td>\n",
       "      <td>LyrAjv8V6HWkceuTB4Xtkw</td>\n",
       "      <td>ujHiaprwCQ5ewziu0Vi9rw</td>\n",
       "      <td>3</td>\n",
       "      <td>The Buffet at Bellagio</td>\n",
       "      <td>NV</td>\n",
       "      <td>4091</td>\n",
       "      <td>Duke</td>\n",
       "      <td>1170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cUo2TvljZu3eo0Sbu0vNXQ</td>\n",
       "      <td>LyrAjv8V6HWkceuTB4Xtkw</td>\n",
       "      <td>rcaPajgKOJC2vo_l3xa42A</td>\n",
       "      <td>3</td>\n",
       "      <td>Bouchon at the Venezia Tower</td>\n",
       "      <td>NV</td>\n",
       "      <td>3743</td>\n",
       "      <td>Duke</td>\n",
       "      <td>1170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HddoeXBzmLBvrNpljFZ8Ag</td>\n",
       "      <td>LyrAjv8V6HWkceuTB4Xtkw</td>\n",
       "      <td>LNGBEEelQx4zbfWnlc66cw</td>\n",
       "      <td>5</td>\n",
       "      <td>Studio B Buffet</td>\n",
       "      <td>NV</td>\n",
       "      <td>2155</td>\n",
       "      <td>Duke</td>\n",
       "      <td>1170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9cykx5-k4UiEAid_3LhF4g</td>\n",
       "      <td>LyrAjv8V6HWkceuTB4Xtkw</td>\n",
       "      <td>7fxebHYUwIF6CakxSr70iQ</td>\n",
       "      <td>4</td>\n",
       "      <td>Carnevino</td>\n",
       "      <td>NV</td>\n",
       "      <td>1347</td>\n",
       "      <td>Duke</td>\n",
       "      <td>1170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  MFILe8F1qzSK_22zQSukxw  LyrAjv8V6HWkceuTB4Xtkw  iCQpiavjjPzJ5_3gPD5Ebg   \n",
       "1  WaCsltXdV1ag_FKY3tR7jQ  LyrAjv8V6HWkceuTB4Xtkw  f4x1YBxkLrZg652xt2KR5g   \n",
       "2  uSxPoQQ7xQj2CH6Oyxu2Zg  LyrAjv8V6HWkceuTB4Xtkw  DkYS3arLOhA8si5uUEmHOw   \n",
       "3  B_qmwryaFoXNHUSqtN3pKA  LyrAjv8V6HWkceuTB4Xtkw  K7lWdNUhCbcnEvI0NhGewg   \n",
       "4  Zodfk1QxukafgD3-jIGbsQ  LyrAjv8V6HWkceuTB4Xtkw  NvKNe9DnQavC9GstglcBJQ   \n",
       "5  pc9hrm9LVKPCe41j-CcdvA  LyrAjv8V6HWkceuTB4Xtkw  MpmFFw0GE_2iRFPdsRpJbA   \n",
       "6  mispDRX2DZTZuGGOznkNIg  LyrAjv8V6HWkceuTB4Xtkw  ujHiaprwCQ5ewziu0Vi9rw   \n",
       "7  cUo2TvljZu3eo0Sbu0vNXQ  LyrAjv8V6HWkceuTB4Xtkw  rcaPajgKOJC2vo_l3xa42A   \n",
       "8  HddoeXBzmLBvrNpljFZ8Ag  LyrAjv8V6HWkceuTB4Xtkw  LNGBEEelQx4zbfWnlc66cw   \n",
       "9  9cykx5-k4UiEAid_3LhF4g  LyrAjv8V6HWkceuTB4Xtkw  7fxebHYUwIF6CakxSr70iQ   \n",
       "\n",
       "   stars                 business_name state  business_review_count user_name  \\\n",
       "0      4                  Secret Pizza    NV                   4078      Duke   \n",
       "1      4            Hash House A Go Go    NV                   5382      Duke   \n",
       "2      4              Earl of Sandwich    NV                   4981      Duke   \n",
       "3      4                  Wicked Spoon    NV                   6446      Duke   \n",
       "4      3                Grand Lux Cafe    NV                   2670      Duke   \n",
       "5      5                  XS Nightclub    NV                   2915      Duke   \n",
       "6      3        The Buffet at Bellagio    NV                   4091      Duke   \n",
       "7      3  Bouchon at the Venezia Tower    NV                   3743      Duke   \n",
       "8      5               Studio B Buffet    NV                   2155      Duke   \n",
       "9      4                     Carnevino    NV                   1347      Duke   \n",
       "\n",
       "   user_review_count  \n",
       "0               1170  \n",
       "1               1170  \n",
       "2               1170  \n",
       "3               1170  \n",
       "4               1170  \n",
       "5               1170  \n",
       "6               1170  \n",
       "7               1170  \n",
       "8               1170  \n",
       "9               1170  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data cleaning (drop unnecessary columns)\n",
    "data = review_business_user[['review_id','user_id', 'business_id', 'stars_review', 'name_business', 'state', 'review_count_business','name_user','review_count_user']]\n",
    "data.columns = ['review_id','user_id', 'business_id', 'stars', 'business_name', 'state', 'business_review_count', 'user_name','user_review_count']\n",
    "print('Data size is', len(data))\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table represents unique variables for each column of our data table. As a result of data merging, the number of unique user is 1,175, and the number of unique restaurants is 304. The number of reviews is 14,711. Restaurants in Ohio have been removed in the course of the data merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14711</td>\n",
       "      <td>14711</td>\n",
       "      <td>14711</td>\n",
       "      <td>14711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1175</td>\n",
       "      <td>304</td>\n",
       "      <td>14711</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>PKEzKWv_FktMm2mGPjwd0Q</td>\n",
       "      <td>FaHADZARwnY4yvlvpnsfGA</td>\n",
       "      <td>lmRSI0gSBt6Gtb7tldPdAg</td>\n",
       "      <td>NV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>159</td>\n",
       "      <td>371</td>\n",
       "      <td>1</td>\n",
       "      <td>13180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       user_id             business_id  \\\n",
       "count                    14711                   14711   \n",
       "unique                    1175                     304   \n",
       "top     PKEzKWv_FktMm2mGPjwd0Q  FaHADZARwnY4yvlvpnsfGA   \n",
       "freq                       159                     371   \n",
       "\n",
       "                     review_id  state  \n",
       "count                    14711  14711  \n",
       "unique                   14711      5  \n",
       "top     lmRSI0gSBt6Gtb7tldPdAg     NV  \n",
       "freq                         1  13180  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the # of unique users, businesses, and reviews \n",
    "data[['user_id', 'business_id', 'review_id','state']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NV    13180\n",
       "AZ     1159\n",
       "NC      242\n",
       "ON       66\n",
       "PA       64\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show a distribution of states\n",
    "data['state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as a CSV file (we can use the csv file next time)\n",
    "data.to_csv('data_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when loading, use the following code:\n",
    "data = pd.read_csv(\"data_final.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index(drop=True) # need to reset index for creating a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, as we describe above, we defined \"E\" and \"ΔE\" (Delta E). Regarding E, we intentionally drop a half of data obtained above at random. Since the entire data we determined to user is 14,711 reviews, E + ΔE should correspond to the entire data. Therefore, the size of E is 7,356 reviews, and the size of ΔE is 7,355 reviews. We will see whether increasing the data (i.e. using data \"E + ΔE\" instead of using data \"E\") improves the performance or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hika1\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning:\n",
      "\n",
      "From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define \"E\" and \"Delta E\"\n",
    "# We will use \"train_test_split\" function\n",
    "\n",
    "# \"E\" is a subset of \"data\"\n",
    "# We will intentionally extract 10,000 samples from data (14,711 samples)\n",
    "data_e, _ = train_test_split(data, train_size=0.5, random_state=95885)\n",
    "data_e.reset_index(drop=True, inplace=True) # need to reset index for the following chunk (creating dictionary)\n",
    "\n",
    "# \"E + DeltaE\" equals to \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='brightpink'>Methodology</font> <a name=\"method\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the cleaned table (user_id, business_id, ratings combinations), we created a user rating matrix in which the rows represent users (user_id) and columns represent restaurants (business_id). After that, we constructed user-based, item-based, content-based recommendation system.   \n",
    "  \n",
    "For user-based and item-based recommendation system, we used Euclidean distance and Pearson coefficient as similarity calculation methodologies. Then, we computed average weighted ratings for each user or item (restaurant) and displayed a recommendation for a certain user.   \n",
    "  \n",
    "For content-based recommendation system, we applied matrix factorization to find the latent features and compute predicted ratings for all users for all items. After that, we made a recommendation for a certain user based on the predicted ratings.   \n",
    "  \n",
    "Additionally, we also tried an ensemble method to merge these recommendation systems. More specifically, we averaged predicted ratings based on user-based (using Euclidean distance and Pearson coefficient respectively), item-based (using Euclidean distance and Pearson coefficient respectively), content-based recommendations for each user for item, and made it as a final predicted ratings.  \n",
    "  \n",
    "As we described above, we tested our algorithms by comparing predicted ratings and actual ratings for existing ratings. To achieve this, we performed 10-fold cross-validation. In each fold, we held out 10% of the data and keep it as a test dataset. Then, we made predictions (recommendations for all users) based on the remaining 90% of the data (i.e. training data) based on each method, and we compared the predicted ratings to the actual ratings in the test data.\n",
    "  \n",
    "Even though we removed users/restaurants which have fewer rating counts, there are some users and restaurants which do not have similar users/restaurants and thus it was not possible to predict ratings for those users. Therefore, not all users' ratings were predicted, regarding user-based and item-based recommendations. (We were able to make predictions for approximately 60% of the cells of the user-item matrix.) On the other hand, the content-based recommendation made predicted ratings for all users for all items by its nature of using factorization.     \n",
    "  \n",
    "Referencing Yao et al. and Sawant, we used RMSE and MAE as the performance measure, and we also examined whether the performance would be improved by adding more data (i.e. whether using data \"E + ΔE\" yields better performance than using data \"E\") to make sure that learning has happened. \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='brightpink'>Performing Machine Learning</font> <a name=\"ML\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='brightpink'>(1) User-based Recommendation</font> <a name=\"userbased\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a dictionary to calculate similarity\n",
    "# create a dictionary ({user, {item: review, item: review, ...}}, ...) \n",
    "# so that we can apply the code provided in class\n",
    "# Below is a function to do so\n",
    "def convert_dict(data):\n",
    "    data_dict = {}\n",
    "    data_dict_size = 0\n",
    "    for i in range(len(data)):\n",
    "        if data['user_id'].loc[i] not in data_dict:\n",
    "            data_dict[data['user_id'].loc[i]] = {data['business_id'].loc[i]:\n",
    "                                                 data['stars'].loc[i]}\n",
    "            data_dict_size += 1\n",
    "        else:\n",
    "            data_dict[data['user_id'].loc[i]].update({data['business_id'].loc[i]:\n",
    "                                                      data['stars'].loc[i]})\n",
    "            data_dict_size += 1\n",
    "    print('# of users in the data', len(data_dict))\n",
    "    print('# of reveiws in the data:', data_dict_size)\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lecture note\n",
    "def user_based_recommendations( prefs, person, similarity=sim.pearson ):\n",
    "    totals={}\n",
    "    simSums={}\n",
    "    for other in prefs:\n",
    "        # don't compare me to myself\n",
    "        if other==person: continue\n",
    "        sim=similarity(prefs,person,other)\n",
    "  \n",
    "        # ignore scores of zero or lower\n",
    "        if sim<=0: continue\n",
    "        for item in prefs[other]:\n",
    "            # only score movies I haven't seen yet\n",
    "            if item not in prefs[person] or prefs[person][item]==0:\n",
    "                # Similarity * Score\n",
    "                totals.setdefault(item,0)\n",
    "                totals[item]+=prefs[other][item]*sim\n",
    "                # Sum of similarities\n",
    "                simSums.setdefault(item,0)\n",
    "                simSums[item]+=sim\n",
    "  \n",
    "    # Create the normalized list\n",
    "    rankings=[(total/simSums[item],item) for item,total in totals.items()]\n",
    "  \n",
    "    # Return the sorted list\n",
    "    rankings.sort()\n",
    "    rankings.reverse()\n",
    "    return rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of users in the data 1175\n",
      "# of reveiws in the data: 14711\n"
     ]
    }
   ],
   "source": [
    "# apply the function of converting a dictionary\n",
    "data_dict = convert_dict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Recommendation for a certain user\n",
    "First, we tried making a recommendation based on user for a certain user as follows. The first result is a raw recommendation which contains only predicted ratings and \"business_id\"s, while the second result is a sophisticated version of recommendation where restaurant information (name, category, city, and state) is joined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5.0, 'JLbgvGM4FXh9zNP4O5ZWjQ'),\n",
       " (4.945856331657512, 'GmdujALb1Nq2RHGr7jhCaA'),\n",
       " (4.914212833329477, 'Xg5qEQiB-7L6kGJ5F4K3bQ'),\n",
       " (4.866936986736669, 'e4NQLZynhSmvwl38hC4m-A'),\n",
       " (4.859813199809862, 'vHz2RLtfUMVRPFmd7VBEHA')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recommendation for a certain user (Top-N items)\n",
    "user_based_recommendations(data_dict,'bLbSNkLggFnqwNNzzq-Ijw', sim.pearson)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a user's name and items' names\n",
    "def user_name(user_id):\n",
    "    return list(users_df[users_df['user_id'] == user_id]['name'])[0]\n",
    "\n",
    "def item_name(item_id):\n",
    "    return list(businesses_df[businesses_df['business_id'] == item_id]['name'])[0]\n",
    "\n",
    "def item_category(item_id):\n",
    "    return list(businesses_df_original[businesses_df_original['business_id'] == item_id]['categories'])[0]\n",
    "\n",
    "def item_location(item_id):\n",
    "    city = list(businesses_df_original[businesses_df_original['business_id'] == item_id]['city'])[0]\n",
    "    state = list(businesses_df_original[businesses_df_original['business_id'] == item_id]['state'])[0]\n",
    "    return '%s, %s' % (city, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user Stefany\n",
      "5.0: Meat & Potatoes (Meat Shops, Food, Gastropubs, Restaurants, Specialty Food, American (New), Steakhouses; Pittsburgh, PA)\n",
      "4.95: Hwaro (Buffets, Barbeque, Restaurants, Korean; Spring Valley, NV)\n",
      "4.91: Little Miss BBQ (Barbeque, Restaurants; Phoenix, AZ)\n",
      "4.87: Backyard Taco (Restaurants, Food, Mexican; Mesa, AZ)\n",
      "4.86: Gordon Ramsay Hell's Kitchen (Restaurants, American (New), Breakfast & Brunch, Burgers; Las Vegas, NV)\n"
     ]
    }
   ],
   "source": [
    "# Let's display top-5 recommendations for user 'bLbSNkLggFnqwNNzzq-Ijw'\n",
    "test_user = 'bLbSNkLggFnqwNNzzq-Ijw'\n",
    "\n",
    "user_rec = pd.DataFrame.from_dict(user_based_recommendations(data_dict,test_user))\n",
    "\n",
    "print('Recommendations for user %s' %user_name(test_user))\n",
    "for i,j in user_based_recommendations(data_dict,test_user)[:5]:\n",
    "    print('%s: %s (%s; %s)' %(round(i,2), item_name(j), item_category(j), item_location(j)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing 10-fold Cross-Validation\n",
    "Second, to test the performance of the item-based recommendation system, we performed 10-fold cross-validation for each similarity calculation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to perform k-cross validation (user-based recommendation)\n",
    "def user_based_cv(data, k=10, test_size=0.1, similarity=sim.pearson):\n",
    "    matrix_size = len(data['user_id'].unique()) * len(data['business_id'].unique())\n",
    "    rmse_values = []\n",
    "    mae_values = []\n",
    "    rmse2_values = []\n",
    "    mae2_values = []\n",
    "    cv_num = 0\n",
    "    ss = ShuffleSplit(n_splits = k, test_size = test_size, random_state = 95885)\n",
    "    \n",
    "    for train_index, test_index in ss.split(data):\n",
    "        # below is each validation process (in this for loop, we will iterate this process k times)\n",
    "        cv_num += 1\n",
    "    \n",
    "        data_train, data_test= data.loc[train_index], data.loc[test_index] # split data into training and test\n",
    "        data_train.reset_index(drop=True, inplace=True) \n",
    "        data_test.reset_index(drop=True, inplace=True) \n",
    "    \n",
    "        ### compute similarity, prediction (recommendation) based on training data\n",
    "        # create a dictionary for training data ({user: {(item: ratings), (item, ratings), ...}, ...})\n",
    "        train_dict = {}\n",
    "        train_dict_size = 0\n",
    "        for i in range(len(data_train)):\n",
    "            if data_train['user_id'].loc[i] not in train_dict:\n",
    "                train_dict[data_train['user_id'].loc[i]] = {data_train['business_id'].loc[i]:\n",
    "                                                            data_train['stars'].loc[i]}\n",
    "                train_dict_size += 1\n",
    "            else:\n",
    "                train_dict[data_train['user_id'].loc[i]].update({data_train['business_id'].loc[i]:\n",
    "                                                                 data_train['stars'].loc[i]})\n",
    "                train_dict_size += 1\n",
    "        \n",
    "        # create a dictionary for predicted data (recommendations for all users) \n",
    "        pred_dict = {}\n",
    "        pred_dict_size = 0\n",
    "        for user in train_dict.keys():\n",
    "            if user.find('_') == 0: # to avoid math domain error (user_id like '_something' will GET AN ERROR)\n",
    "                pass\n",
    "            elif len(user_based_recommendations(train_dict,user,similarity)) > 0: \n",
    "                for pred, item in user_based_recommendations(train_dict,user,similarity):\n",
    "                    if user not in pred_dict:\n",
    "                        pred_dict[user] = {item: pred}\n",
    "                        pred_dict_size += 1\n",
    "                    else:\n",
    "                        pred_dict[user].update({item: pred})\n",
    "                        pred_dict_size += 1\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        ### compute RMSE and MAE by comparing predicted ratings to test data\n",
    "        # create a dictionary for test data\n",
    "        test_dict = {}\n",
    "        test_dict_size = 0\n",
    "        for i in range(len(data_test)):\n",
    "            if data_test['user_id'].loc[i] not in test_dict:\n",
    "                test_dict[data_test['user_id'].loc[i]] = {data_test['business_id'].loc[i]:\n",
    "                                                          data_test['stars'].loc[i]}\n",
    "                test_dict_size += 1\n",
    "            else:\n",
    "                test_dict[data_test['user_id'].loc[i]].update({data_test['business_id'].loc[i]:\n",
    "                                                               data_test['stars'].loc[i]})\n",
    "                test_dict_size += 1\n",
    "\n",
    "        # compareing test data to predicted data and calculate errors\n",
    "        sum_squared_error = 0\n",
    "        sum_absolute_error = 0\n",
    "        sum_squared_error2 = 0\n",
    "        sum_absolute_error2 = 0\n",
    "        error_count = 0\n",
    "        count = 0\n",
    "        for user in test_dict.keys():\n",
    "            if user in pred_dict.keys():\n",
    "                for item in test_dict[user].keys():\n",
    "                    if item in pred_dict[user].keys():\n",
    "                        sum_squared_error += (pred_dict[user][item] - test_dict[user][item]) ** 2\n",
    "                        sum_absolute_error += abs(pred_dict[user][item] - test_dict[user][item])\n",
    "                        # Adjusted SE and AE (predicted ratings will be rounded because actual ratings are integer)\n",
    "                        sum_squared_error2 += (round(pred_dict[user][item],0) - test_dict[user][item]) ** 2\n",
    "                        sum_absolute_error2 += abs(round(pred_dict[user][item],0) - test_dict[user][item])\n",
    "                        if (round(pred_dict[user][item],0) - test_dict[user][item]) != 0:\n",
    "                            error_count += 1\n",
    "                        count += 1\n",
    "\n",
    "        rmse = math.sqrt(sum_squared_error / count)\n",
    "        mae = sum_absolute_error / count\n",
    "        rmse2 = math.sqrt(sum_squared_error2 / count)\n",
    "        mae2 = sum_absolute_error2 / count\n",
    "        print(cv_num)\n",
    "        print('User-Item Matrix size', matrix_size)\n",
    "        print('Review data size collected for calculating prediction (training data)', train_dict_size)\n",
    "        print('Review data size predicted (recommendations made)', pred_dict_size)\n",
    "        print('Review data size for testing (test data size)', test_dict_size)\n",
    "        print('Review data size used for testing (test data compared to predictions): ', count)\n",
    "        print('# of errors: ', error_count)\n",
    "        print ('RMSE: ', rmse)\n",
    "        print ('MAE: ', mae)\n",
    "        print('Adjusted RMSE: ', rmse2)\n",
    "        print('Adjusted MAE: ', mae2)\n",
    "        print ()\n",
    "        rmse_values.append(rmse)\n",
    "        mae_values.append(mae)\n",
    "        rmse2_values.append(rmse2)\n",
    "        mae2_values.append(mae2)\n",
    "\n",
    "    mean_rmse = np.mean(rmse_values)\n",
    "    mean_mae = np.mean(mae_values)\n",
    "    mean_rmse2 = np.mean(rmse2_values)\n",
    "    mean_mae2 = np.mean(mae2_values)\n",
    "    print ('Overall performance')\n",
    "    print ('Mean RMSE: %s' % round(mean_rmse,4))\n",
    "    print ('Mean MAE: %s' % round(mean_mae,4))\n",
    "    print ('Mean Adjusted RMSE: %s' % round(mean_rmse2,4))\n",
    "    print ('Mean Adjusted MAE: %s' % round(mean_mae2,4))\n",
    "    return mean_rmse, mean_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing 10-fold Cross Validation - using Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 254494\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  710\n",
      "# of errors:  421\n",
      "RMSE:  0.9251828014012471\n",
      "MAE:  0.73634669304642\n",
      "Adjusted RMSE:  0.982236596953283\n",
      "Adjusted MAE:  0.7112676056338029\n",
      "\n",
      "2\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 255773\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  700\n",
      "# of errors:  399\n",
      "RMSE:  0.8917628758392866\n",
      "MAE:  0.6998026145389744\n",
      "Adjusted RMSE:  0.933503385868831\n",
      "Adjusted MAE:  0.6628571428571428\n",
      "\n",
      "3\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 255524\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  699\n",
      "# of errors:  413\n",
      "RMSE:  0.9620369349409834\n",
      "MAE:  0.7425238995574993\n",
      "Adjusted RMSE:  1.0078376688781423\n",
      "Adjusted MAE:  0.7181688125894135\n",
      "\n",
      "4\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 254741\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  690\n",
      "# of errors:  393\n",
      "RMSE:  0.9654363735664891\n",
      "MAE:  0.7411348245566968\n",
      "Adjusted RMSE:  0.9949146056138527\n",
      "Adjusted MAE:  0.6942028985507246\n",
      "\n",
      "5\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 255627\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  707\n",
      "# of errors:  389\n",
      "RMSE:  0.957153850273987\n",
      "MAE:  0.7334463581574467\n",
      "Adjusted RMSE:  0.9871880829780992\n",
      "Adjusted MAE:  0.6803394625176803\n",
      "\n",
      "6\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 256221\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  702\n",
      "# of errors:  409\n",
      "RMSE:  0.9491885066611002\n",
      "MAE:  0.7456243988891909\n",
      "Adjusted RMSE:  0.9747525071229364\n",
      "Adjusted MAE:  0.6965811965811965\n",
      "\n",
      "7\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 253614\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  693\n",
      "# of errors:  401\n",
      "RMSE:  0.9214915473016201\n",
      "MAE:  0.7281249176756432\n",
      "Adjusted RMSE:  0.9542190055400859\n",
      "Adjusted MAE:  0.6825396825396826\n",
      "\n",
      "8\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 254621\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  703\n",
      "# of errors:  414\n",
      "RMSE:  0.9215369444461159\n",
      "MAE:  0.7235347287236998\n",
      "Adjusted RMSE:  0.9630440122647732\n",
      "Adjusted MAE:  0.6884779516358464\n",
      "\n",
      "9\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 255468\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  700\n",
      "# of errors:  387\n",
      "RMSE:  0.9183964556085311\n",
      "MAE:  0.7045004448424161\n",
      "Adjusted RMSE:  0.9464218328601077\n",
      "Adjusted MAE:  0.6557142857142857\n",
      "\n",
      "10\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 254626\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  694\n",
      "# of errors:  401\n",
      "RMSE:  0.947502737074311\n",
      "MAE:  0.7323727403272257\n",
      "Adjusted RMSE:  0.9818232759743256\n",
      "Adjusted MAE:  0.6902017291066282\n",
      "\n",
      "Overall performance\n",
      "Mean RMSE: 0.936\n",
      "Mean MAE: 0.7287\n",
      "Mean Adjusted RMSE: 0.9726\n",
      "Mean Adjusted MAE: 0.688\n"
     ]
    }
   ],
   "source": [
    "# k-fold Cross Validation - Euclidean Coefficient\n",
    "# \"E\"\n",
    "user_based_e1_r, user_based_e1_a = user_based_cv(data_e, k=10, test_size=0.1, similarity=sim.euclidean_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 324072\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1442\n",
      "# of errors:  779\n",
      "RMSE:  0.9004538702625948\n",
      "MAE:  0.6947860735385905\n",
      "Adjusted RMSE:  0.9220672667342669\n",
      "Adjusted MAE:  0.6352288488210819\n",
      "\n",
      "2\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 323218\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1439\n",
      "# of errors:  823\n",
      "RMSE:  0.9273070680586617\n",
      "MAE:  0.7247329608532421\n",
      "Adjusted RMSE:  0.9526671531316754\n",
      "Adjusted MAE:  0.6768589298123697\n",
      "\n",
      "3\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 323377\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1445\n",
      "# of errors:  819\n",
      "RMSE:  0.8916940917240964\n",
      "MAE:  0.6932866123176226\n",
      "Adjusted RMSE:  0.9363848615801837\n",
      "Adjusted MAE:  0.6622837370242215\n",
      "\n",
      "4\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 325449\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1447\n",
      "# of errors:  793\n",
      "RMSE:  0.859040041655216\n",
      "MAE:  0.6668200733137835\n",
      "Adjusted RMSE:  0.8934221728785423\n",
      "Adjusted MAE:  0.6254319281271596\n",
      "\n",
      "5\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 322277\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1438\n",
      "# of errors:  790\n",
      "RMSE:  0.8758160092984594\n",
      "MAE:  0.6789259249460795\n",
      "Adjusted RMSE:  0.9180616940008199\n",
      "Adjusted MAE:  0.6411682892906815\n",
      "\n",
      "6\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 321960\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1431\n",
      "# of errors:  792\n",
      "RMSE:  0.9089755596540103\n",
      "MAE:  0.7032386999888754\n",
      "Adjusted RMSE:  0.930874268772509\n",
      "Adjusted MAE:  0.649895178197065\n",
      "\n",
      "7\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 324871\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1440\n",
      "# of errors:  789\n",
      "RMSE:  0.87510191907542\n",
      "MAE:  0.6812028878037801\n",
      "Adjusted RMSE:  0.9071475440448851\n",
      "Adjusted MAE:  0.6326388888888889\n",
      "\n",
      "8\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 323660\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1447\n",
      "# of errors:  804\n",
      "RMSE:  0.893193563214258\n",
      "MAE:  0.6925711509059161\n",
      "Adjusted RMSE:  0.9249666125205905\n",
      "Adjusted MAE:  0.6482377332411887\n",
      "\n",
      "9\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 323125\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1439\n",
      "# of errors:  827\n",
      "RMSE:  0.9114156646019121\n",
      "MAE:  0.7090642612619165\n",
      "Adjusted RMSE:  0.9482803278904779\n",
      "Adjusted MAE:  0.6740792216817234\n",
      "\n",
      "10\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 324891\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1445\n",
      "# of errors:  828\n",
      "RMSE:  0.8839842190365799\n",
      "MAE:  0.6967467023531925\n",
      "Adjusted RMSE:  0.9135655839208083\n",
      "Adjusted MAE:  0.6532871972318339\n",
      "\n",
      "Overall performance\n",
      "Mean RMSE: 0.8927\n",
      "Mean MAE: 0.6941\n",
      "Mean Adjusted RMSE: 0.9247\n",
      "Mean Adjusted MAE: 0.6499\n"
     ]
    }
   ],
   "source": [
    "# k-fold Cross Validation - Euclidean Coefficient\n",
    "# \"E + Delta E\"\n",
    "user_based_e2_r, user_based_e2_a = user_based_cv(data, k=10, test_size=0.1, similarity=sim.euclidean_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing 10-fold Cross Validation - using Pearson Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 89910\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  499\n",
      "# of errors:  287\n",
      "RMSE:  0.9798744123974474\n",
      "MAE:  0.7515958367035621\n",
      "Adjusted RMSE:  1.0079841586693\n",
      "Adjusted MAE:  0.7114228456913828\n",
      "\n",
      "2\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 91078\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  518\n",
      "# of errors:  314\n",
      "RMSE:  1.0159066483316244\n",
      "MAE:  0.7769875986381115\n",
      "Adjusted RMSE:  1.0554144275589632\n",
      "Adjusted MAE:  0.7586872586872587\n",
      "\n",
      "3\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 89240\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  521\n",
      "# of errors:  308\n",
      "RMSE:  1.0437276717466504\n",
      "MAE:  0.7783806465393704\n",
      "Adjusted RMSE:  1.0767121347478368\n",
      "Adjusted MAE:  0.7562380038387716\n",
      "\n",
      "4\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 91842\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  491\n",
      "# of errors:  301\n",
      "RMSE:  1.0446392467211627\n",
      "MAE:  0.798477276209642\n",
      "Adjusted RMSE:  1.0679557722903266\n",
      "Adjusted MAE:  0.7617107942973523\n",
      "\n",
      "5\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 91069\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  497\n",
      "# of errors:  304\n",
      "RMSE:  1.0503185426490864\n",
      "MAE:  0.8033338838721965\n",
      "Adjusted RMSE:  1.0765471296390159\n",
      "Adjusted MAE:  0.7766599597585513\n",
      "\n",
      "6\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 90254\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  499\n",
      "# of errors:  294\n",
      "RMSE:  1.0466161260555533\n",
      "MAE:  0.7866438512169434\n",
      "Adjusted RMSE:  1.0743875544860286\n",
      "Adjusted MAE:  0.7535070140280561\n",
      "\n",
      "7\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 89346\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  491\n",
      "# of errors:  291\n",
      "RMSE:  0.9968957656621824\n",
      "MAE:  0.7729947717962152\n",
      "Adjusted RMSE:  1.009123351677189\n",
      "Adjusted MAE:  0.725050916496945\n",
      "\n",
      "8\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 90384\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  504\n",
      "# of errors:  299\n",
      "RMSE:  1.0202851934021935\n",
      "MAE:  0.7815911528783568\n",
      "Adjusted RMSE:  1.0455878577403088\n",
      "Adjusted MAE:  0.7400793650793651\n",
      "\n",
      "9\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 89042\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  511\n",
      "# of errors:  322\n",
      "RMSE:  1.0239743464215558\n",
      "MAE:  0.7984515498285034\n",
      "Adjusted RMSE:  1.0726998329014736\n",
      "Adjusted MAE:  0.7906066536203522\n",
      "\n",
      "10\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 91709\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  494\n",
      "# of errors:  301\n",
      "RMSE:  1.0515512806265785\n",
      "MAE:  0.7944159443552413\n",
      "Adjusted RMSE:  1.0872838795907045\n",
      "Adjusted MAE:  0.7813765182186235\n",
      "\n",
      "Overall performance\n",
      "Mean RMSE: 1.0274\n",
      "Mean MAE: 0.7843\n",
      "Mean Adjusted RMSE: 1.0574\n",
      "Mean Adjusted MAE: 0.7555\n"
     ]
    }
   ],
   "source": [
    "# k-fold Cross Validation - Pearson Coefficient\n",
    "# \"E\"\n",
    "user_based_p1_r, user_based_p1_a = user_based_cv(data_e, k=10, test_size=0.1, similarity=sim.pearson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 225295\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1374\n",
      "# of errors:  774\n",
      "RMSE:  0.930348815535313\n",
      "MAE:  0.7198373692897118\n",
      "Adjusted RMSE:  0.9595152827729312\n",
      "Adjusted MAE:  0.6746724890829694\n",
      "\n",
      "2\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 226752\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1387\n",
      "# of errors:  809\n",
      "RMSE:  0.9565317137653999\n",
      "MAE:  0.7532257793271337\n",
      "Adjusted RMSE:  0.9832776288809904\n",
      "Adjusted MAE:  0.702956020187455\n",
      "\n",
      "3\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 222598\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1355\n",
      "# of errors:  807\n",
      "RMSE:  0.9311449396878868\n",
      "MAE:  0.7261785834471592\n",
      "Adjusted RMSE:  0.9760981137545942\n",
      "Adjusted MAE:  0.7018450184501845\n",
      "\n",
      "4\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 224713\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1375\n",
      "# of errors:  769\n",
      "RMSE:  0.8823559952492144\n",
      "MAE:  0.685390407885396\n",
      "Adjusted RMSE:  0.9200790479874295\n",
      "Adjusted MAE:  0.6458181818181818\n",
      "\n",
      "5\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 223680\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1367\n",
      "# of errors:  759\n",
      "RMSE:  0.9118724937330647\n",
      "MAE:  0.7041307616367931\n",
      "Adjusted RMSE:  0.9589222186950043\n",
      "Adjusted MAE:  0.6664228237015362\n",
      "\n",
      "6\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 226230\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1375\n",
      "# of errors:  788\n",
      "RMSE:  0.9294200788612011\n",
      "MAE:  0.725200128053246\n",
      "Adjusted RMSE:  0.9610600208292734\n",
      "Adjusted MAE:  0.6821818181818182\n",
      "\n",
      "7\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 225396\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1380\n",
      "# of errors:  773\n",
      "RMSE:  0.9101962669277204\n",
      "MAE:  0.7094612834910572\n",
      "Adjusted RMSE:  0.9440891630699332\n",
      "Adjusted MAE:  0.6608695652173913\n",
      "\n",
      "8\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 224475\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1381\n",
      "# of errors:  785\n",
      "RMSE:  0.9206710335223015\n",
      "MAE:  0.7123596021278482\n",
      "Adjusted RMSE:  0.9502467380331543\n",
      "Adjusted MAE:  0.6712527154236061\n",
      "\n",
      "9\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 224298\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1354\n",
      "# of errors:  779\n",
      "RMSE:  0.9348786442680298\n",
      "MAE:  0.7238470447383212\n",
      "Adjusted RMSE:  0.9627477908127957\n",
      "Adjusted MAE:  0.6831610044313147\n",
      "\n",
      "10\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 223046\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1365\n",
      "# of errors:  806\n",
      "RMSE:  0.9277531932883722\n",
      "MAE:  0.7274954170413478\n",
      "Adjusted RMSE:  0.9687422456265332\n",
      "Adjusted MAE:  0.6967032967032967\n",
      "\n",
      "Overall performance\n",
      "Mean RMSE: 0.9235\n",
      "Mean MAE: 0.7187\n",
      "Mean Adjusted RMSE: 0.9585\n",
      "Mean Adjusted MAE: 0.6786\n"
     ]
    }
   ],
   "source": [
    "# k-fold Cross Validation - Pearson Coefficient\n",
    "# \"E + Delta E\"\n",
    "user_based_p2_r, user_based_p2_a = user_based_cv(data, k=10, test_size=0.1, similarity=sim.pearson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the performance of user-based recommendations (when we use the entire data (\"E + Delta E\") is approximately 0.9 for RMSE and 0.7 for MAE. Adjusted RMSE and MAE here are RMSE and MAE when we round the predicted ratings (for example, predicted ratings 4.6 should be 5.) because ratings in Yelp are interger. Comparing the rounded predicted ratings and actual ratings, we found that approximately a half of predictions matched the actual ratings in the test data; however, performances were not better than ordinary RMSE and MAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='brightpink'>(2) Item-based Recommendation</font> <a name=\"itembased\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we developed item-based recommendation system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the lecture material\n",
    "def transpose( users ):\n",
    "    result={}\n",
    "    for person in users:\n",
    "        for item in users[person]:\n",
    "            result.setdefault(item,{})        \n",
    "            # Flip item and person\n",
    "            result[item][person] = users[person][item]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar( users, person, n=5, similarity=sim.pearson ):\n",
    "    sims=[(similarity(users, person, other), other) for other in users if other!=person]\n",
    "    sims.sort()\n",
    "    sims.reverse()\n",
    "#    return sims[0:n]\n",
    "    return sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the lecture material\n",
    "def similarity_between_items( prefs, n=10, similarity=sim.pearson ):\n",
    "    result={}\n",
    "    # Invert the preference matrix to be item-centric\n",
    "    item_prefs = transpose( prefs )\n",
    "    len_item_prefs = len(item_prefs)\n",
    "    c=0\n",
    "    for item in item_prefs:\n",
    "        # Status updates for large datasets\n",
    "        c+=1\n",
    "#        if c%100==0: print( \"%d / %d\" % (c,len_item_prefs) )\n",
    "        # Find the most similar items to this one\n",
    "        scores = most_similar( item_prefs, item, n, similarity )\n",
    "        result[item] = scores\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the lecture material\n",
    "def item_based_recommendations( prefs, itemMatch, user ):\n",
    "    userRatings=prefs[user]\n",
    "    scores={}\n",
    "    totalSim={}\n",
    "    # Loop over items rated by this user\n",
    "    for (item,rating) in userRatings.items( ):\n",
    "  \n",
    "      # Loop over items similar to this one\n",
    "      for (similarity,item2) in itemMatch[item]:\n",
    "        \n",
    "        # ignore scores of zero or lower (this line is added to the original)\n",
    "        if similarity<=0: continue\n",
    "  \n",
    "        # Ignore if this user has already rated this item\n",
    "        if item2 in userRatings: continue\n",
    "        # Weighted sum of rating times similarity\n",
    "        scores.setdefault(item2,0)\n",
    "        scores[item2]+=similarity*rating\n",
    "        # Sum of all the similarities\n",
    "        totalSim.setdefault(item2,0)\n",
    "        totalSim[item2]+=similarity\n",
    "  \n",
    "    # Divide each total score by total weighting to get an average\n",
    "    rankings=[(score/totalSim[item],item) for item,score in scores.items( )]\n",
    "  \n",
    "    # Return the rankings from highest to lowest\n",
    "    rankings.sort( )\n",
    "    rankings.reverse( )\n",
    "    return rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A recommendation for a certain user\n",
    "First, we tried making a recommendation based on item for a certain user as follows. The first result is a raw recommendation which contains only predicted ratings and \"business_id\"s, while the second result is a sophisticated version of recommendation where restaurant information (name, category, city, and state) is joined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lecture note\n",
    "from pprint import pprint as pp\n",
    "def pt( expr ):\n",
    "    print()\n",
    "    print(\"=== \" + expr)\n",
    "    val = eval(expr)\n",
    "    pp(val)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4.178039500119352, 'gG9z6zr_49LocyCTvSFg0w'),\n",
       " (3.9910769726489415, 'sJNcipFYElitBrtiJx0ezQ'),\n",
       " (3.9662568472203255, 'T2tEMLpTeSMxLKpxwFdS3g'),\n",
       " (3.902307108867529, 'mnwRtuVQEsIUomBchu0gwg'),\n",
       " (3.8588734981107162, 'FogTa-wmjhVnJCoTiaxvZA')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For user_id 'bLbSNkLggFnqwNNzzq-Ijw'\n",
    "itemsim = similarity_between_items( data_dict, similarity = sim.pearson )\n",
    "if itemsim == None: itemsim = similarity_between_items( data_dict )\n",
    "test_user = 'bLbSNkLggFnqwNNzzq-Ijw'\n",
    "\n",
    "item_rec = pd.DataFrame.from_dict(item_based_recommendations(data_dict, itemsim, test_user))\n",
    "#pt( \"item_based_recommendations( data_dict, itemsim, 'bLbSNkLggFnqwNNzzq-Ijw' )[:5]\" )\n",
    "item_based_recommendations(data_dict, itemsim, test_user)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user Stefany\n",
      "4.18: Amélie's French Bakery & Café (Bakeries, Patisserie/Cake Shop, Restaurants, Breakfast & Brunch, Food, Cafes, Coffee & Tea; Charlotte, NC)\n",
      "3.99: Arizona Wilderness Brewing (Food, Breweries, American (New), Burgers, Restaurants; Gilbert, AZ)\n",
      "3.97: Cabo Fish Taco (Latin American, Seafood, Restaurants, Mexican; Charlotte, NC)\n",
      "3.9: OHSO Brewery- Arcadia (American (Traditional), American (New), Breweries, Breakfast & Brunch, Restaurants, Food, Gluten-Free; Phoenix, AZ)\n",
      "3.86: Postino Central (Wine Bars, Nightlife, Italian, Bars, Restaurants, Breakfast & Brunch; Phoenix, AZ)\n"
     ]
    }
   ],
   "source": [
    "# Let's display top-5 recommendations for user 'bLbSNkLggFnqwNNzzq-Ijw'\n",
    "test_user = 'bLbSNkLggFnqwNNzzq-Ijw'\n",
    "\n",
    "print('Recommendations for user %s' %user_name(test_user))\n",
    "for i,j in item_based_recommendations(data_dict, itemsim, test_user)[:5]:\n",
    "    print('%s: %s (%s; %s)' %(round(i,2), item_name(j), item_category(j), item_location(j)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing 10-fold Cross-Validation\n",
    "Second, we performed 10-fold cross-validation to examine the performance of the recommendation system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to perform k-cross validation (item-based recommendation)\n",
    "def item_based_cv(data, k=10, test_size=0.1, similarity=sim.pearson):\n",
    "    matrix_size = len(data['user_id'].unique()) * len(data['business_id'].unique())\n",
    "    rmse_values = []\n",
    "    mae_values = []\n",
    "    rmse2_values = []\n",
    "    mae2_values = []\n",
    "    cv_num = 0\n",
    "    ss = ShuffleSplit(n_splits=k, test_size=test_size, random_state=95885)\n",
    "    for train_index, test_index in ss.split(data):\n",
    "        # below is each validation process (in this for loop, we will iterate this process k times)\n",
    "        cv_num += 1\n",
    "    \n",
    "        data_train, data_test= data.loc[train_index], data.loc[test_index] # split data into training and test\n",
    "        data_train.reset_index(drop=True, inplace=True) \n",
    "        data_test.reset_index(drop=True, inplace=True) \n",
    "    \n",
    "        ### compute similarity, prediction (recommendation) based on training data\n",
    "        train_dict = {}\n",
    "        train_dict_size = 0\n",
    "        for i in range(len(data_train)):\n",
    "            if data_train['user_id'].loc[i] not in train_dict:\n",
    "                train_dict[data_train['user_id'].loc[i]] = {data_train['business_id'].loc[i]:\n",
    "                                                            data_train['stars'].loc[i]}\n",
    "                train_dict_size += 1\n",
    "            else:\n",
    "                train_dict[data_train['user_id'].loc[i]].update({data_train['business_id'].loc[i]:\n",
    "                                                                 data_train['stars'].loc[i]})\n",
    "                train_dict_size += 1\n",
    "\n",
    "        itemsim = similarity_between_items( train_dict, similarity= similarity )\n",
    "        pred_dict = {}\n",
    "        pred_dict_size = 0\n",
    "        for user in train_dict.keys():\n",
    "            if user.find('_') == 0: # to avoid math domain error (user_id like '_something' will GET AN ERROR)\n",
    "                pass\n",
    "            elif len(item_based_recommendations(train_dict, itemsim, user)) > 0: \n",
    "                for pred, item in item_based_recommendations(train_dict, itemsim, user):\n",
    "                    if user not in pred_dict:\n",
    "                        if pred is None: continue\n",
    "                        pred_dict[user] = {item: pred}\n",
    "                        pred_dict_size += 1\n",
    "                    else:\n",
    "                        if pred is None: continue\n",
    "                        pred_dict[user].update({item: pred})\n",
    "                        pred_dict_size += 1\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        ### compute RMSE and MAE by comparing predicted ratings to test data\n",
    "        test_dict = {}\n",
    "        test_dict_size = 0\n",
    "        for i in range(len(data_test)):\n",
    "            if data_test['user_id'].loc[i] not in test_dict:\n",
    "                test_dict[data_test['user_id'].loc[i]] = {data_test['business_id'].loc[i]:\n",
    "                                                          data_test['stars'].loc[i]}\n",
    "                test_dict_size += 1\n",
    "            else:\n",
    "                test_dict[data_test['user_id'].loc[i]].update({data_test['business_id'].loc[i]:\n",
    "                                                               data_test['stars'].loc[i]})\n",
    "                test_dict_size += 1\n",
    "\n",
    "        sum_squared_error = 0\n",
    "        sum_absolute_error = 0\n",
    "        sum_squared_error2 = 0\n",
    "        sum_absolute_error2 = 0\n",
    "        error_count = 0\n",
    "        count = 0\n",
    "        for user in test_dict.keys():\n",
    "            if user in pred_dict.keys():\n",
    "                for item in test_dict[user].keys():\n",
    "                    if item in pred_dict[user].keys():\n",
    "                        sum_squared_error += (pred_dict[user][item] - test_dict[user][item]) ** 2\n",
    "                        sum_absolute_error += abs(pred_dict[user][item] - test_dict[user][item])\n",
    "                        # Adjusted SE and AE (predicted ratings will be rounded because actual ratings are integer)\n",
    "                        sum_squared_error2 += (round(pred_dict[user][item],0) - test_dict[user][item]) ** 2\n",
    "                        sum_absolute_error2 += abs(round(pred_dict[user][item],0) - test_dict[user][item])\n",
    "                        if (round(pred_dict[user][item],0) - test_dict[user][item]) != 0:\n",
    "                            error_count += 1\n",
    "                        count += 1\n",
    "\n",
    "        rmse = math.sqrt(sum_squared_error / count)\n",
    "        mae = sum_absolute_error / count\n",
    "        rmse2 = math.sqrt(sum_squared_error2 / count)\n",
    "        mae2 = sum_absolute_error2 / count\n",
    "        print(cv_num)\n",
    "        print('User-Item Matrix size', matrix_size)\n",
    "        print('Review data size collected for calculating prediction (training data)', train_dict_size)\n",
    "        print('Review data size predicted (recommendations made)', pred_dict_size)\n",
    "        print('Review data size for testing (test data size)', test_dict_size)\n",
    "        print('Review data size used for testing (test data compared to predictions): ', count)\n",
    "        print('# of errors: ', error_count)\n",
    "        print ('RMSE: ', rmse)\n",
    "        print ('MAE: ', mae)\n",
    "        print('Adjusted RMSE: ', rmse2)\n",
    "        print('Adjusted MAE: ', mae2)\n",
    "        print ()\n",
    "        rmse_values.append(rmse)\n",
    "        mae_values.append(mae)\n",
    "        rmse2_values.append(rmse2)\n",
    "        mae2_values.append(mae2)\n",
    "\n",
    "    mean_rmse = np.mean(rmse_values)\n",
    "    mean_mae = np.mean(mae_values)\n",
    "    mean_rmse2 = np.mean(rmse2_values)\n",
    "    mean_mae2 = np.mean(mae2_values)\n",
    "    print ('Overall performance')\n",
    "    print ('Mean RMSE: %s' % round(mean_rmse,4))\n",
    "    print ('Mean MAE: %s' % round(mean_mae,4))\n",
    "    print ('Mean Adjusted RMSE: %s' % round(mean_rmse2,4))\n",
    "    print ('Mean Adjusted MAE: %s' % round(mean_mae2,4))\n",
    "    return mean_rmse, mean_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing 10-fold Cross-Validation - using Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 254494\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  710\n",
      "# of errors:  450\n",
      "RMSE:  1.0105765786917964\n",
      "MAE:  0.7949506902614089\n",
      "Adjusted RMSE:  1.0467925524607653\n",
      "Adjusted MAE:  0.7774647887323943\n",
      "\n",
      "2\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 255773\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  700\n",
      "# of errors:  399\n",
      "RMSE:  0.9355632983329635\n",
      "MAE:  0.7337087069157181\n",
      "Adjusted RMSE:  0.972478424292429\n",
      "Adjusted MAE:  0.6885714285714286\n",
      "\n",
      "3\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 255524\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  699\n",
      "# of errors:  415\n",
      "RMSE:  0.9799086518935984\n",
      "MAE:  0.7667112232442371\n",
      "Adjusted RMSE:  1.0127936971374643\n",
      "Adjusted MAE:  0.7281831187410587\n",
      "\n",
      "4\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 254741\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  690\n",
      "# of errors:  443\n",
      "RMSE:  1.00356556636107\n",
      "MAE:  0.7989968484048149\n",
      "Adjusted RMSE:  1.0446551334416956\n",
      "Adjusted MAE:  0.7782608695652173\n",
      "\n",
      "5\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 255627\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  707\n",
      "# of errors:  423\n",
      "RMSE:  1.0288506208974764\n",
      "MAE:  0.791744004722956\n",
      "Adjusted RMSE:  1.0557313103802097\n",
      "Adjusted MAE:  0.7581329561527581\n",
      "\n",
      "6\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 256221\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  702\n",
      "# of errors:  431\n",
      "RMSE:  0.9785960687046263\n",
      "MAE:  0.767671098120529\n",
      "Adjusted RMSE:  1.0246255656860948\n",
      "Adjusted MAE:  0.7507122507122507\n",
      "\n",
      "7\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 253614\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  693\n",
      "# of errors:  415\n",
      "RMSE:  1.007158263033534\n",
      "MAE:  0.7686112031692536\n",
      "Adjusted RMSE:  1.0629534937475533\n",
      "Adjusted MAE:  0.7604617604617605\n",
      "\n",
      "8\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 254621\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  703\n",
      "# of errors:  419\n",
      "RMSE:  1.0226221797190471\n",
      "MAE:  0.7944656936306689\n",
      "Adjusted RMSE:  1.0660945597093254\n",
      "Adjusted MAE:  0.7581792318634424\n",
      "\n",
      "9\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 255468\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  700\n",
      "# of errors:  423\n",
      "RMSE:  0.9729260222667465\n",
      "MAE:  0.7596338305528735\n",
      "Adjusted RMSE:  1.0288690045731907\n",
      "Adjusted MAE:  0.7471428571428571\n",
      "\n",
      "10\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 254626\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  694\n",
      "# of errors:  425\n",
      "RMSE:  1.009694137941115\n",
      "MAE:  0.7849470202782638\n",
      "Adjusted RMSE:  1.043713167394427\n",
      "Adjusted MAE:  0.7550432276657061\n",
      "\n",
      "Overall performance\n",
      "Mean RMSE: 0.9949\n",
      "Mean MAE: 0.7761\n",
      "Mean Adjusted RMSE: 1.0359\n",
      "Mean Adjusted MAE: 0.7502\n"
     ]
    }
   ],
   "source": [
    "# k-fold Cross Validation - Euclidean Coefficient\n",
    "# \"E\"\n",
    "item_based_e1_r, item_based_e1_a = item_based_cv(data_e, k=10, test_size=0.1, similarity=sim.euclidean_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 324072\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1442\n",
      "# of errors:  823\n",
      "RMSE:  0.980408896910211\n",
      "MAE:  0.7519187176266195\n",
      "Adjusted RMSE:  1.011034816824909\n",
      "Adjusted MAE:  0.7059639389736477\n",
      "\n",
      "2\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 323218\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1439\n",
      "# of errors:  858\n",
      "RMSE:  0.975683197779086\n",
      "MAE:  0.7668984978068507\n",
      "Adjusted RMSE:  1.028435191789405\n",
      "Adjusted MAE:  0.7407922168172342\n",
      "\n",
      "3\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 323377\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1445\n",
      "# of errors:  859\n",
      "RMSE:  0.9783394281536202\n",
      "MAE:  0.7626619625991549\n",
      "Adjusted RMSE:  1.015110746169904\n",
      "Adjusted MAE:  0.7259515570934256\n",
      "\n",
      "4\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 325449\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1447\n",
      "# of errors:  822\n",
      "RMSE:  0.948525968627579\n",
      "MAE:  0.7328539734321533\n",
      "Adjusted RMSE:  0.9888808218837225\n",
      "Adjusted MAE:  0.6931582584657913\n",
      "\n",
      "5\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 322277\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1438\n",
      "# of errors:  840\n",
      "RMSE:  0.9755410161356803\n",
      "MAE:  0.7542597657340523\n",
      "Adjusted RMSE:  1.0175784612970582\n",
      "Adjusted MAE:  0.719749652294854\n",
      "\n",
      "6\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 321960\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1431\n",
      "# of errors:  825\n",
      "RMSE:  1.0128944555072161\n",
      "MAE:  0.7782933930371085\n",
      "Adjusted RMSE:  1.0427614791724147\n",
      "Adjusted MAE:  0.726764500349406\n",
      "\n",
      "7\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 324871\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1440\n",
      "# of errors:  846\n",
      "RMSE:  0.9580576151928987\n",
      "MAE:  0.7508511482132872\n",
      "Adjusted RMSE:  1.0024276089130382\n",
      "Adjusted MAE:  0.7145833333333333\n",
      "\n",
      "8\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 323660\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1447\n",
      "# of errors:  849\n",
      "RMSE:  0.9509882900496474\n",
      "MAE:  0.7424329263930577\n",
      "Adjusted RMSE:  0.9892301880214138\n",
      "Adjusted MAE:  0.7076710435383552\n",
      "\n",
      "9\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 323125\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1439\n",
      "# of errors:  852\n",
      "RMSE:  1.005487167833401\n",
      "MAE:  0.7849434786495578\n",
      "Adjusted RMSE:  1.0445264196173623\n",
      "Adjusted MAE:  0.7463516330785267\n",
      "\n",
      "10\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 324891\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1445\n",
      "# of errors:  879\n",
      "RMSE:  0.9703660403739274\n",
      "MAE:  0.7651868447414911\n",
      "Adjusted RMSE:  1.0147698189575447\n",
      "Adjusted MAE:  0.7377162629757785\n",
      "\n",
      "Overall performance\n",
      "Mean RMSE: 0.9756\n",
      "Mean MAE: 0.759\n",
      "Mean Adjusted RMSE: 1.0155\n",
      "Mean Adjusted MAE: 0.7219\n"
     ]
    }
   ],
   "source": [
    "# k-fold Cross Validation - Euclidean Coefficient\n",
    "# \"E + Delta E\"\n",
    "item_based_e2_r, item_based_e2_a = item_based_cv(data, k=10, test_size=0.1, similarity=sim.euclidean_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing 10-fold Cross Validation - Using Pearson Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 112938\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  539\n",
      "# of errors:  344\n",
      "RMSE:  1.1286065269881032\n",
      "MAE:  0.8653687168403592\n",
      "Adjusted RMSE:  1.1605769149479943\n",
      "Adjusted MAE:  0.849721706864564\n",
      "\n",
      "2\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 115555\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  566\n",
      "# of errors:  350\n",
      "RMSE:  1.0278246371131576\n",
      "MAE:  0.7967155447101802\n",
      "Adjusted RMSE:  1.074109048164954\n",
      "Adjusted MAE:  0.7826855123674912\n",
      "\n",
      "3\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 112548\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  561\n",
      "# of errors:  352\n",
      "RMSE:  1.074922849408872\n",
      "MAE:  0.8311563821818634\n",
      "Adjusted RMSE:  1.1226083708788215\n",
      "Adjusted MAE:  0.8146167557932263\n",
      "\n",
      "4\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 114666\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  545\n",
      "# of errors:  364\n",
      "RMSE:  1.1047367987088252\n",
      "MAE:  0.8555279831800591\n",
      "Adjusted RMSE:  1.1325055440656568\n",
      "Adjusted MAE:  0.8495412844036697\n",
      "\n",
      "5\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 114700\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  570\n",
      "# of errors:  330\n",
      "RMSE:  1.1164122319880272\n",
      "MAE:  0.8220522075879545\n",
      "Adjusted RMSE:  1.1440157034868714\n",
      "Adjusted MAE:  0.7929824561403509\n",
      "\n",
      "6\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 114139\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  580\n",
      "# of errors:  364\n",
      "RMSE:  1.1052548354610099\n",
      "MAE:  0.8457204326662924\n",
      "Adjusted RMSE:  1.1394190897422096\n",
      "Adjusted MAE:  0.8224137931034483\n",
      "\n",
      "7\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 113556\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  554\n",
      "# of errors:  352\n",
      "RMSE:  1.0306263846268124\n",
      "MAE:  0.800151419558399\n",
      "Adjusted RMSE:  1.0815151826269973\n",
      "Adjusted MAE:  0.7978339350180506\n",
      "\n",
      "8\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 114316\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  557\n",
      "# of errors:  340\n",
      "RMSE:  1.034285176606238\n",
      "MAE:  0.7920794303370478\n",
      "Adjusted RMSE:  1.0592839965175895\n",
      "Adjusted MAE:  0.7666068222621185\n",
      "\n",
      "9\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 113204\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  579\n",
      "# of errors:  345\n",
      "RMSE:  1.0899486741148507\n",
      "MAE:  0.8238893371154525\n",
      "Adjusted RMSE:  1.1096997368860213\n",
      "Adjusted MAE:  0.7858376511226253\n",
      "\n",
      "10\n",
      "User-Item Matrix size 319504\n",
      "Review data size collected for calculating prediction (training data) 6619\n",
      "Review data size predicted (recommendations made) 114082\n",
      "Review data size for testing (test data size) 736\n",
      "Review data size used for testing (test data compared to predictions):  548\n",
      "# of errors:  356\n",
      "RMSE:  1.0719642722679579\n",
      "MAE:  0.8378568411355163\n",
      "Adjusted RMSE:  1.114764876521954\n",
      "Adjusted MAE:  0.8266423357664233\n",
      "\n",
      "Overall performance\n",
      "Mean RMSE: 1.0785\n",
      "Mean MAE: 0.8271\n",
      "Mean Adjusted RMSE: 1.1138\n",
      "Mean Adjusted MAE: 0.8089\n"
     ]
    }
   ],
   "source": [
    "# k-fold Cross Validation - Pearson Coefficient\n",
    "# \"E\"\n",
    "item_based_p1_r, item_based_p1_a= item_based_cv(data_e, k=10, test_size=0.1, similarity=sim.pearson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 255436\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1402\n",
      "# of errors:  815\n",
      "RMSE:  1.0008772097173766\n",
      "MAE:  0.7708764785746939\n",
      "Adjusted RMSE:  1.038488971436182\n",
      "Adjusted MAE:  0.7289586305278174\n",
      "\n",
      "2\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 255493\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1407\n",
      "# of errors:  843\n",
      "RMSE:  1.0057382613533727\n",
      "MAE:  0.7824120341989728\n",
      "Adjusted RMSE:  1.0495878637466403\n",
      "Adjusted MAE:  0.7562189054726368\n",
      "\n",
      "3\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 254154\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1410\n",
      "# of errors:  837\n",
      "RMSE:  0.9914470446407786\n",
      "MAE:  0.7642931175417487\n",
      "Adjusted RMSE:  1.0269420280999382\n",
      "Adjusted MAE:  0.7312056737588652\n",
      "\n",
      "4\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 255396\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1410\n",
      "# of errors:  830\n",
      "RMSE:  0.987925208877278\n",
      "MAE:  0.7623973073775624\n",
      "Adjusted RMSE:  1.0220963022454537\n",
      "Adjusted MAE:  0.7269503546099291\n",
      "\n",
      "5\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 253329\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1407\n",
      "# of errors:  835\n",
      "RMSE:  1.011089380859326\n",
      "MAE:  0.7785858529606428\n",
      "Adjusted RMSE:  1.051279384366646\n",
      "Adjusted MAE:  0.7455579246624022\n",
      "\n",
      "6\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 255468\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1405\n",
      "# of errors:  825\n",
      "RMSE:  1.0201845922311863\n",
      "MAE:  0.7819412683317262\n",
      "Adjusted RMSE:  1.0614567308463754\n",
      "Adjusted MAE:  0.7480427046263345\n",
      "\n",
      "7\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 256374\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1400\n",
      "# of errors:  837\n",
      "RMSE:  1.0051907432390517\n",
      "MAE:  0.7819227981938205\n",
      "Adjusted RMSE:  1.031295994645295\n",
      "Adjusted MAE:  0.7392857142857143\n",
      "\n",
      "8\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 254150\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1411\n",
      "# of errors:  840\n",
      "RMSE:  0.9673754985660517\n",
      "MAE:  0.7556390687058229\n",
      "Adjusted RMSE:  1.003890377202667\n",
      "Adjusted MAE:  0.7228915662650602\n",
      "\n",
      "9\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 252958\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1401\n",
      "# of errors:  865\n",
      "RMSE:  1.0272416855901925\n",
      "MAE:  0.8089352706669322\n",
      "Adjusted RMSE:  1.0706652391139662\n",
      "Adjusted MAE:  0.7822983583154889\n",
      "\n",
      "10\n",
      "User-Item Matrix size 357200\n",
      "Review data size collected for calculating prediction (training data) 13239\n",
      "Review data size predicted (recommendations made) 255685\n",
      "Review data size for testing (test data size) 1472\n",
      "Review data size used for testing (test data compared to predictions):  1414\n",
      "# of errors:  857\n",
      "RMSE:  1.002064162934536\n",
      "MAE:  0.7817629420237332\n",
      "Adjusted RMSE:  1.0408896205953269\n",
      "Adjusted MAE:  0.7538896746817539\n",
      "\n",
      "Overall performance\n",
      "Mean RMSE: 1.0019\n",
      "Mean MAE: 0.7769\n",
      "Mean Adjusted RMSE: 1.0397\n",
      "Mean Adjusted MAE: 0.7435\n"
     ]
    }
   ],
   "source": [
    "# k-fold Cross Validation - Pearson Coefficient\n",
    "# \"E + Delta E\"\n",
    "item_based_p2_r, item_based_p2_a= item_based_cv(data, k=10, test_size=0.1, similarity=sim.pearson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the performance of item-based recommendations (when we use the entire data (\"E + Delta E\") is approximately 1.0 for RMSE and 0.77-0.78 for MAE. Adjusted RMSE and MAE here are again RMSE and MAE when we round the predicted ratings. Similar to user-based recommendations, comparing the rounded predicted ratings and actual ratings, we found that approximately a half of predictions matched the actual ratings in the test data; however, performances were not better than ordinary RMSE and MAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='brightpink'>Content-Based Recommendation</font> <a name=\"contentbased\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a recommendation for a certain user\n",
    "First, we tried making a recommendation based on content (latent features of restaurants) for a certain user as follows. The first result is a raw recommendation which contains only predicted ratings and \"business_id\"s, while the second result is a sophisticated version of recommendation where restaurant information (name, category, city, and state) is joined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hika1\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning:\n",
      "\n",
      "Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 515.447127\n",
      "         Iterations: 3000\n",
      "         Function evaluations: 4464\n",
      "         Gradient evaluations: 4464\n"
     ]
    }
   ],
   "source": [
    "# User-item matrix (this will take a few minutes)\n",
    "user_ratings_mat = pd.pivot_table(data[['user_id', 'business_id', 'stars']], \n",
    "                                  index='user_id', columns='business_id',\n",
    "                                  aggfunc=np.max) # , fill_value=0) # aggfunc= lambda x: s\n",
    "\n",
    "# Apply matrix factorization to find the latent features (This may take a few minutes)\n",
    "# Convert the dataframe \"matrix\" to a real 2D numpy matrix\n",
    "mat = user_ratings_mat.as_matrix()\n",
    "U, M = m.low_rank_matrix_factorization(mat, num_features=15, regularization_amount=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a predicted \n",
    "predicted_ratings_np = np.matmul(U, M)\n",
    "\n",
    "# Convert the numpy matrix into a dataframe for easy viewing\n",
    "predicted_ratings_df = pd.DataFrame(index     = user_ratings_mat.index,\n",
    "                                    columns   = user_ratings_mat.columns,\n",
    "                                    data      = predicted_ratings_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the below to a userID\n",
    "user_id_to_search = 'bLbSNkLggFnqwNNzzq-Ijw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a recommendation for user bLbSNkLggFnqwNNzzq-Ijw\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>predicted_stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5shgJB7a-2_gdnzc0gsOtg</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>J4CATH00YZrq8Bne2S4_cw</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oVrvzUJczq0e2JzVxSTyag</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KmuLLSyZJdNoarwcIERHcw</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>o7AiTlyWUrBSzdz6oMHj5w</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>r5PLDU-4mSbde5XekTXSCA</td>\n",
       "      <td>4.776193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>77h11eWv6HKJAgojLx8G4w</td>\n",
       "      <td>4.748403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GI-CAiZ_Gg3h21PwrANB4Q</td>\n",
       "      <td>4.743096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pSQFynH1VxkfSmehRXlZWw</td>\n",
       "      <td>4.734429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>IWKtGvVg4hqc9rWHjW8KoA</td>\n",
       "      <td>4.648800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>JzOp695tclcNCNMuBl7oxA</td>\n",
       "      <td>4.514314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7ibuDLfx8gEhESAufYIySw</td>\n",
       "      <td>4.507369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>u4sTiCzVeIHZY8OlaL346Q</td>\n",
       "      <td>4.436438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>OARQDsxyoGnnX2FfSl9HjA</td>\n",
       "      <td>4.406307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>iGEvDk6hsizigmXhDKs2Vg</td>\n",
       "      <td>4.374001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               business_id  predicted_stars\n",
       "0   5shgJB7a-2_gdnzc0gsOtg         5.000000\n",
       "1   J4CATH00YZrq8Bne2S4_cw         5.000000\n",
       "2   oVrvzUJczq0e2JzVxSTyag         5.000000\n",
       "3   KmuLLSyZJdNoarwcIERHcw         5.000000\n",
       "4   o7AiTlyWUrBSzdz6oMHj5w         5.000000\n",
       "5   r5PLDU-4mSbde5XekTXSCA         4.776193\n",
       "6   77h11eWv6HKJAgojLx8G4w         4.748403\n",
       "7   GI-CAiZ_Gg3h21PwrANB4Q         4.743096\n",
       "8   pSQFynH1VxkfSmehRXlZWw         4.734429\n",
       "9   IWKtGvVg4hqc9rWHjW8KoA         4.648800\n",
       "10  JzOp695tclcNCNMuBl7oxA         4.514314\n",
       "11  7ibuDLfx8gEhESAufYIySw         4.507369\n",
       "12  u4sTiCzVeIHZY8OlaL346Q         4.436438\n",
       "13  OARQDsxyoGnnX2FfSl9HjA         4.406307\n",
       "14  iGEvDk6hsizigmXhDKs2Vg         4.374001"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewed_business_df = data[data['user_id'] == user_id_to_search]\n",
    "user_ratings = predicted_ratings_df.loc[user_id_to_search].reset_index(level=0, drop=True)\n",
    "\n",
    "already_reviewed = reviewed_business_df['business_id'] # business_ids which have alreadly been reviewed\n",
    "recommended_df = user_ratings[user_ratings.index.isin(already_reviewed) == False] # extract only unreviewed items\n",
    "recommended_df = recommended_df.sort_values(ascending=False) # sort by predicted ratings\n",
    "\n",
    "# if predicted_stars is above 5.0 (such as 6.16), convert it into 5.0.\n",
    "recommended_df[recommended_df>5] = 5\n",
    "# if predicted_stars is below 1 (such as -0.4), convert it into 1.0\n",
    "recommended_df[recommended_df<1] = 1\n",
    "\n",
    "recommended_df = recommended_df.reset_index() # convert index column into an ordinary column \n",
    "recommended_df.columns = ['business_id','predicted_stars'] # change the second column name\n",
    "content_rec = recommended_df[['predicted_stars', 'business_id']] # This will be used later\n",
    "\n",
    "# print the output\n",
    "print(\"This is a recommendation for user %s\" %user_id_to_search)\n",
    "recommended_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user Stefany\n",
      "5.0: Firefly (Restaurants, Tapas/Small Plates, Tapas Bars; Las Vegas, NV)\n",
      "5.0: CUT by Wolfgang Puck (Bars, Nightlife, Restaurants, Lounges, Steakhouses; Las Vegas, NV)\n",
      "5.0: Cirque du Soleil - Zumanity (Adult Entertainment, Nightlife, Performing Arts, Arts & Entertainment; Las Vegas, NV)\n",
      "5.0: Cirque du Soleil - Mystère (Performing Arts, Arts & Entertainment; Las Vegas, NV)\n",
      "5.0: Excalibur Hotel (Event Planning & Services, Casinos, Hotels, Resorts, Arts & Entertainment, Hotels & Travel; Las Vegas, NV)\n"
     ]
    }
   ],
   "source": [
    "# Let's display top-5 recommendations for user 'bLbSNkLggFnqwNNzzq-Ijw'\n",
    "print('Recommendations for user %s' %user_name(user_id_to_search))\n",
    "for i in range(5):\n",
    "    item = recommended_df.loc[i]['business_id']\n",
    "    pred = recommended_df.loc[i]['predicted_stars']\n",
    "    print('%s: %s (%s; %s)' %(round(pred,2), item_name(item), item_category(item), item_location(item)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing 10-fold Cross-Validation\n",
    "Next, we performed 10-fold Cross-Validation to test the performance of the content-based recommendation system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to perform k-cross validation (content-based recommendation)\n",
    "def content_based_cv(data, k = 10, test_size = 0.1):\n",
    "    matrix_size = len(data['user_id'].unique()) * len(data['business_id'].unique())\n",
    "    rmse_values = []\n",
    "    mae_values = []\n",
    "    rmse2_values = []\n",
    "    mae2_values = []\n",
    "    rmse3_values = []\n",
    "    mae3_values = []\n",
    "    cv_num = 0\n",
    "    ss = ShuffleSplit(n_splits=k, test_size=test_size, random_state=95885)\n",
    "\n",
    "    for train_index, test_index in ss.split(data):\n",
    "        # below is each validation process (in this for loop, we will iterate this process k times)\n",
    "        cv_num += 1\n",
    "    \n",
    "        data_train, data_test= data.loc[train_index], data.loc[test_index] # split data into training and test\n",
    "        data_train.reset_index(drop=True, inplace=True) \n",
    "        data_test.reset_index(drop=True, inplace=True) \n",
    "    \n",
    "        ### make predictions (recommendation) based on training data by factorization\n",
    "        # User-item matrix\n",
    "        user_ratings_mat_train = pd.pivot_table(data_train[['user_id', 'business_id', 'stars']], \n",
    "                                          index='user_id', columns='business_id',\n",
    "                                          aggfunc=np.max) # , fill_value=0)   \n",
    "        # Apply matrix factorization to find the latent features\n",
    "        # Now, we convert the dataframe \"matrix\" to a real 2D numpy matrix\n",
    "        mat = user_ratings_mat_train.as_matrix()\n",
    "        # This spolit matrix U: 100*a M: a*34 a: attributes of the movies\n",
    "        U, M = m.low_rank_matrix_factorization(mat, num_features=15, regularization_amount=0.1)\n",
    "        predicted_ratings_np = np.matmul(U, M)\n",
    "        # Convert the numpy matrix into a dataframe for easy viewing\n",
    "        predicted_ratings_df = pd.DataFrame(index     = user_ratings_mat_train.index,\n",
    "                                            columns   = user_ratings_mat_train.columns,\n",
    "                                            data      = predicted_ratings_np)\n",
    "    \n",
    "        ### compute RMSE and MAE by comparing predicted ratings to test data\n",
    "        # convert test data into User-item matrix\n",
    "        user_ratings_mat_test = pd.pivot_table(data_test[['user_id', 'business_id', 'stars']], \n",
    "                                          index='user_id', columns='business_id',\n",
    "                                          aggfunc=np.max) # , fill_value=0) \n",
    "        # Compare test data to predicted data and calculate RMSE and MAE\n",
    "        sum_squared_error = 0\n",
    "        sum_absolute_error = 0\n",
    "        sum_squared_error2 = 0\n",
    "        sum_absolute_error2 = 0\n",
    "        sum_squared_error3 = 0\n",
    "        sum_absolute_error3 = 0\n",
    "        count = 0\n",
    "        error_count = 0\n",
    "        error_count2 = 0\n",
    "        for i in range(len(user_ratings_mat_test)): # loop in the test data to look for actual ratings\n",
    "            for j in range(len(user_ratings_mat_test.columns)):\n",
    "                test_stars = user_ratings_mat_test.loc[user_ratings_mat_test.index[i]].values[j]\n",
    "                if test_stars > 0 : # to eliminate np.nan values\n",
    "                    user = user_ratings_mat_test.index[i]\n",
    "                    business = user_ratings_mat_test.columns[j][1]\n",
    "                    if user in predicted_ratings_df.index: # to exclude users do not exist in the training data\n",
    "                        pred_stars = predicted_ratings_df.loc[user]['stars'][business] # look for the coressponding predicted ratings\n",
    "                        # Simple SE and AE\n",
    "                        error = pred_stars - test_stars\n",
    "                        sum_squared_error += error ** 2\n",
    "                        sum_absolute_error += abs(error)\n",
    "                        # Adjusted SE and AE (predicted ratings will be rounded because actual ratings are integer)\n",
    "                        sum_squared_error2 += (round(pred_stars, 0) - test_stars) ** 2\n",
    "                        sum_absolute_error2 += abs(round(pred_stars, 0) - test_stars)\n",
    "                        if (round(pred_stars, 0) - test_stars) != 0:\n",
    "                            error_count += 1\n",
    "                        # Adjusted SE and AE ver.2 (predicted ratings > 5 or < 1 will be converted into 5 and 1, respectively)\n",
    "                        if pred_stars > 5:\n",
    "                            pred_stars = 5\n",
    "                        if pred_stars < 1:\n",
    "                            pred_stars = 1\n",
    "                        error = pred_stars - test_stars\n",
    "                        sum_squared_error3 += error ** 2\n",
    "                        sum_absolute_error3 += abs(error)\n",
    "                        if (round(pred_stars, 0) - test_stars) != 0:\n",
    "                            error_count2 += 1\n",
    "                        count += 1\n",
    "        rmse = math.sqrt(sum_squared_error / count)\n",
    "        mae = sum_absolute_error / count\n",
    "        rmse2 = math.sqrt(sum_squared_error2 / count)\n",
    "        mae2 = sum_absolute_error2 / count\n",
    "        rmse3 = math.sqrt(sum_squared_error3 / count)\n",
    "        mae3 = sum_absolute_error3 / count\n",
    "        print(cv_num)\n",
    "        print('Test data size used: ', count)\n",
    "        print('# of errors: ', error_count)\n",
    "        print('# of errors (with UL and LL): ', error_count2)\n",
    "        print('RMSE: ', rmse)\n",
    "        print('MAE: ', mae)\n",
    "        print('Adjusted RMSE: ', rmse2)\n",
    "        print('Adjusted MAE: ', mae2)\n",
    "        print('RMSE (with UL and LL): ', rmse3)\n",
    "        print('MAE (with UL and LL): ', mae3)\n",
    "        rmse_values.append(rmse)\n",
    "        mae_values.append(mae)\n",
    "        rmse2_values.append(rmse2)\n",
    "        mae2_values.append(mae2)\n",
    "        rmse3_values.append(rmse3)\n",
    "        mae3_values.append(mae3)\n",
    "    \n",
    "    # report the final results\n",
    "    mean_rmse = np.mean(rmse_values)\n",
    "    mean_mae = np.mean(mae_values)\n",
    "    mean_rmse2 = np.mean(rmse2_values)\n",
    "    mean_mae2 = np.mean(mae2_values)\n",
    "    mean_rmse3 = np.mean(rmse3_values)\n",
    "    mean_mae3 = np.mean(mae3_values)\n",
    "    print ('Overall performance')\n",
    "    print ('Mean RMSE: %s' % round(mean_rmse,4))\n",
    "    print ('Mean MAE: %s' % round(mean_mae,4))\n",
    "    print ('Mean Adjusted RMSE: %s' % round(mean_rmse2,4))\n",
    "    print ('Mean Adjusted MAE: %s' % round(mean_mae2,4))\n",
    "    print ('Mean RMSE (with UL and LL): %s' % round(mean_rmse3,4))\n",
    "    print ('Mean MAE (with UL and LL): %s' % round(mean_mae3,4))\n",
    "    return mean_rmse3, mean_mae3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hika1\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: FutureWarning:\n",
      "\n",
      "Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 257.849864\n",
      "         Iterations: 3000\n",
      "         Function evaluations: 4455\n",
      "         Gradient evaluations: 4455\n",
      "1\n",
      "Test data size used:  725\n",
      "# of errors:  516\n",
      "# of errors (with UL and LL):  513\n",
      "RMSE:  1.28801544450036\n",
      "MAE:  1.026657865018809\n",
      "Adjusted RMSE:  1.3282085419972582\n",
      "Adjusted MAE:  1.016551724137931\n",
      "RMSE (with UL and LL):  1.269447300350302\n",
      "MAE (with UL and LL):  1.0085969471630296\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 258.096917\n",
      "         Iterations: 3000\n",
      "         Function evaluations: 4473\n",
      "         Gradient evaluations: 4473\n",
      "2\n",
      "Test data size used:  718\n",
      "# of errors:  492\n",
      "# of errors (with UL and LL):  487\n",
      "RMSE:  1.2373434423658634\n",
      "MAE:  0.9949136299237505\n",
      "Adjusted RMSE:  1.2765290683707688\n",
      "Adjusted MAE:  0.9693593314763231\n",
      "RMSE (with UL and LL):  1.2170190552396714\n",
      "MAE (with UL and LL):  0.9743832346199363\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 257.693728\n",
      "         Iterations: 3000\n",
      "         Function evaluations: 4473\n",
      "         Gradient evaluations: 4473\n",
      "3\n",
      "Test data size used:  718\n",
      "# of errors:  519\n",
      "# of errors (with UL and LL):  513\n",
      "RMSE:  1.2930274244964295\n",
      "MAE:  1.050331665828613\n",
      "Adjusted RMSE:  1.3183935527332418\n",
      "Adjusted MAE:  1.0222841225626742\n",
      "RMSE (with UL and LL):  1.2730279427281885\n",
      "MAE (with UL and LL):  1.0290223639428056\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 256.772342\n",
      "         Iterations: 3000\n",
      "         Function evaluations: 4449\n",
      "         Gradient evaluations: 4449\n",
      "4\n",
      "Test data size used:  713\n",
      "# of errors:  518\n",
      "# of errors (with UL and LL):  512\n",
      "RMSE:  1.3251904960855962\n",
      "MAE:  1.0635214744545332\n",
      "Adjusted RMSE:  1.3734611432150015\n",
      "Adjusted MAE:  1.064516129032258\n",
      "RMSE (with UL and LL):  1.3074595248647016\n",
      "MAE (with UL and LL):  1.0421715936287301\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 258.417559\n",
      "         Iterations: 3000\n",
      "         Function evaluations: 4472\n",
      "         Gradient evaluations: 4472\n",
      "5\n",
      "Test data size used:  722\n",
      "# of errors:  503\n",
      "# of errors (with UL and LL):  495\n",
      "RMSE:  1.2845484688047406\n",
      "MAE:  1.0210767579574633\n",
      "Adjusted RMSE:  1.3408146529323155\n",
      "Adjusted MAE:  1.0193905817174516\n",
      "RMSE (with UL and LL):  1.257084245888809\n",
      "MAE (with UL and LL):  0.9930501118324019\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 258.186693\n",
      "         Iterations: 3000\n",
      "         Function evaluations: 4496\n",
      "         Gradient evaluations: 4496\n",
      "6\n",
      "Test data size used:  720\n",
      "# of errors:  488\n",
      "# of errors (with UL and LL):  480\n",
      "RMSE:  1.2858366366054883\n",
      "MAE:  1.0189962280505087\n",
      "Adjusted RMSE:  1.3038404810405297\n",
      "Adjusted MAE:  0.975\n",
      "RMSE (with UL and LL):  1.2692375158986051\n",
      "MAE (with UL and LL):  0.9995788761841928\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 258.070567\n",
      "         Iterations: 3000\n",
      "         Function evaluations: 4458\n",
      "         Gradient evaluations: 4458\n",
      "7\n",
      "Test data size used:  714\n",
      "# of errors:  489\n",
      "# of errors (with UL and LL):  484\n",
      "RMSE:  1.2411804304845635\n",
      "MAE:  0.9883155967212177\n",
      "Adjusted RMSE:  1.2674551577988125\n",
      "Adjusted MAE:  0.9593837535014006\n",
      "RMSE (with UL and LL):  1.2264218720326632\n",
      "MAE (with UL and LL):  0.9717037828531729\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 256.438105\n",
      "         Iterations: 3000\n",
      "         Function evaluations: 4471\n",
      "         Gradient evaluations: 4471\n",
      "8\n",
      "Test data size used:  714\n",
      "# of errors:  498\n",
      "# of errors (with UL and LL):  496\n",
      "RMSE:  1.33239040923763\n",
      "MAE:  1.0585439138428556\n",
      "Adjusted RMSE:  1.35245393735279\n",
      "Adjusted MAE:  1.022408963585434\n",
      "RMSE (with UL and LL):  1.3094635073056056\n",
      "MAE (with UL and LL):  1.0392153631381236\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 257.779652\n",
      "         Iterations: 3000\n",
      "         Function evaluations: 4473\n",
      "         Gradient evaluations: 4473\n",
      "9\n",
      "Test data size used:  719\n",
      "# of errors:  501\n",
      "# of errors (with UL and LL):  496\n",
      "RMSE:  1.2630318064199224\n",
      "MAE:  1.0083537811313614\n",
      "Adjusted RMSE:  1.312187442087094\n",
      "Adjusted MAE:  1.004172461752434\n",
      "RMSE (with UL and LL):  1.2501797340328749\n",
      "MAE (with UL and LL):  0.9929399028626574\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 257.516420\n",
      "         Iterations: 3000\n",
      "         Function evaluations: 4502\n",
      "         Gradient evaluations: 4502\n",
      "10\n",
      "Test data size used:  717\n",
      "# of errors:  484\n",
      "# of errors (with UL and LL):  477\n",
      "RMSE:  1.2598136783617049\n",
      "MAE:  1.0018932408232892\n",
      "Adjusted RMSE:  1.2920743271753397\n",
      "Adjusted MAE:  0.9721059972105998\n",
      "RMSE (with UL and LL):  1.2407529500222407\n",
      "MAE (with UL and LL):  0.9818772120640548\n",
      "Overall performance\n",
      "Mean RMSE: 1.281\n",
      "Mean MAE: 1.0233\n",
      "Mean Adjusted RMSE: 1.3165\n",
      "Mean Adjusted MAE: 1.0025\n",
      "Mean RMSE (with UL and LL): 1.262\n",
      "Mean MAE (with UL and LL): 1.0033\n"
     ]
    }
   ],
   "source": [
    "# \"E\"\n",
    "# This may take more than 10 minutes mostly because factorization takes some time\n",
    "content_based_f1_r, content_based_f1_a = content_based_cv(data_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hika1\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 413.959488\n",
      "         Iterations: 3000\n",
      "         Function evaluations: 4493\n",
      "         Gradient evaluations: 4493\n",
      "1\n",
      "Test data size used:  1456\n",
      "# of errors:  1082\n",
      "# of errors (with UL and LL):  1039\n",
      "RMSE:  1.6567707838277357\n",
      "MAE:  1.2790509255431364\n",
      "Adjusted RMSE:  1.6760268297571892\n",
      "Adjusted MAE:  1.2554945054945055\n",
      "RMSE (with UL and LL):  1.4104134132767392\n",
      "MAE (with UL and LL):  1.109626596856603\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 413.385389\n",
      "         Iterations: 3000\n",
      "         Function evaluations: 4482\n",
      "         Gradient evaluations: 4482\n",
      "2\n",
      "Test data size used:  1454\n",
      "# of errors:  1092\n",
      "# of errors (with UL and LL):  1057\n",
      "RMSE:  1.671512066361165\n",
      "MAE:  1.2986549096528055\n",
      "Adjusted RMSE:  1.7022115237322366\n",
      "Adjusted MAE:  1.2840440165061897\n",
      "RMSE (with UL and LL):  1.4592043258588772\n",
      "MAE (with UL and LL):  1.1485097409202598\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 419.148504\n",
      "         Iterations: 3000\n",
      "         Function evaluations: 4477\n",
      "         Gradient evaluations: 4477\n",
      "3\n",
      "Test data size used:  1458\n",
      "# of errors:  1099\n",
      "# of errors (with UL and LL):  1048\n",
      "RMSE:  1.7067324783862166\n",
      "MAE:  1.314127594757965\n",
      "Adjusted RMSE:  1.7371910221568256\n",
      "Adjusted MAE:  1.3017832647462277\n",
      "RMSE (with UL and LL):  1.4638896521771931\n",
      "MAE (with UL and LL):  1.1439906019449977\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 417.918738\n",
      "         Iterations: 3000\n",
      "         Function evaluations: 4477\n",
      "         Gradient evaluations: 4477\n",
      "4\n",
      "Test data size used:  1461\n",
      "# of errors:  1083\n",
      "# of errors (with UL and LL):  1043\n",
      "RMSE:  1.7074373225196138\n",
      "MAE:  1.3136372379829455\n",
      "Adjusted RMSE:  1.730864877400689\n",
      "Adjusted MAE:  1.2888432580424367\n",
      "RMSE (with UL and LL):  1.462224786551926\n",
      "MAE (with UL and LL):  1.1403658985419864\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 420.840231\n",
      "         Iterations: 3000\n",
      "         Function evaluations: 4492\n",
      "         Gradient evaluations: 4492\n",
      "5\n",
      "Test data size used:  1451\n",
      "# of errors:  1081\n",
      "# of errors (with UL and LL):  1043\n",
      "RMSE:  1.6513404698235497\n",
      "MAE:  1.2857235934135172\n",
      "Adjusted RMSE:  1.6748021062522052\n",
      "Adjusted MAE:  1.2598208132322537\n",
      "RMSE (with UL and LL):  1.4326627035558772\n",
      "MAE (with UL and LL):  1.1307032162911055\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 419.218808\n",
      "         Iterations: 3000\n",
      "         Function evaluations: 4512\n",
      "         Gradient evaluations: 4512\n",
      "6\n",
      "Test data size used:  1445\n",
      "# of errors:  1092\n",
      "# of errors (with UL and LL):  1044\n",
      "RMSE:  1.6664882809570203\n",
      "MAE:  1.30014669500586\n",
      "Adjusted RMSE:  1.6908055859299036\n",
      "Adjusted MAE:  1.280968858131488\n",
      "RMSE (with UL and LL):  1.4459329186661039\n",
      "MAE (with UL and LL):  1.1341491474307515\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 421.454990\n",
      "         Iterations: 3000\n",
      "         Function evaluations: 4491\n",
      "         Gradient evaluations: 4491\n",
      "7\n",
      "Test data size used:  1459\n",
      "# of errors:  1087\n",
      "# of errors (with UL and LL):  1046\n",
      "RMSE:  1.6681696408380544\n",
      "MAE:  1.2944959594232337\n",
      "Adjusted RMSE:  1.6840989195011198\n",
      "Adjusted MAE:  1.26525017135024\n",
      "RMSE (with UL and LL):  1.4224500182257567\n",
      "MAE (with UL and LL):  1.1231972083978965\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 418.013887\n",
      "         Iterations: 3000\n",
      "         Function evaluations: 4480\n",
      "         Gradient evaluations: 4480\n",
      "8\n",
      "Test data size used:  1457\n",
      "# of errors:  1056\n",
      "# of errors (with UL and LL):  1018\n",
      "RMSE:  1.620693730039017\n",
      "MAE:  1.2560008446714932\n",
      "Adjusted RMSE:  1.6515212097059009\n",
      "Adjusted MAE:  1.2299245024021963\n",
      "RMSE (with UL and LL):  1.4233469978085487\n",
      "MAE (with UL and LL):  1.1160842186809177\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 418.363441\n",
      "         Iterations: 3000\n",
      "         Function evaluations: 4464\n",
      "         Gradient evaluations: 4464\n",
      "9\n",
      "Test data size used:  1453\n",
      "# of errors:  1073\n",
      "# of errors (with UL and LL):  1039\n",
      "RMSE:  1.6471070569458124\n",
      "MAE:  1.2829095263579102\n",
      "Adjusted RMSE:  1.669119553114081\n",
      "Adjusted MAE:  1.2525808671713696\n",
      "RMSE (with UL and LL):  1.4338340896114072\n",
      "MAE (with UL and LL):  1.1328740289160848\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 417.516575\n",
      "         Iterations: 3000\n",
      "         Function evaluations: 4468\n",
      "         Gradient evaluations: 4468\n",
      "10\n",
      "Test data size used:  1456\n",
      "# of errors:  1091\n",
      "# of errors (with UL and LL):  1056\n",
      "RMSE:  1.6899835344374243\n",
      "MAE:  1.3124018920259382\n",
      "Adjusted RMSE:  1.7143143312629765\n",
      "Adjusted MAE:  1.2918956043956045\n",
      "RMSE (with UL and LL):  1.4771476342472118\n",
      "MAE (with UL and LL):  1.1580556766534558\n",
      "Overall performance\n",
      "Mean RMSE: 1.6686\n",
      "Mean MAE: 1.2937\n",
      "Mean Adjusted RMSE: 1.6931\n",
      "Mean Adjusted MAE: 1.2711\n",
      "Mean RMSE (with UL and LL): 1.4431\n",
      "Mean MAE (with UL and LL): 1.1338\n"
     ]
    }
   ],
   "source": [
    "# \"E + Delta E\"\n",
    "# This may take more than 20 minutes partly because factorization takes some time\n",
    "content_based_f2_r, content_based_f2_a = content_based_cv(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the performance of content-based recommendations (when we use the entire data (\"E + Delta E\") is approximately 1.7 for RMSE and 1.3 for MAE. Adjusted RMSE and MAE here are RMSE and MAE when we round the predicted ratings. Similar to user-based recommendations, comparing the rounded predicted ratings and actual ratings, we found that only less than a half of predictions matched the actual ratings in the test data. RMSE and MAE \"with UL and LL\" are RMASE and MAE that are calculated based on \"regulalized\" predicted ratings. Since the range of ratings in Yelp is from 1 to 5, it is reasonable to replace predicted ratings above 5 and below 1 with 5 and 1, respectively. (Factorization predicts ratings so that it can minimize RMAE for existing ratings, and of course it does not know ratings in Yelp must be between 1 an 5. Thus, it is likely that there are some predicted ratings less than 1.0 or more than 5.0.) As a result, RMSE and MAE \"with UL and LL\" is approximately 1.4 and 1.3. We used these values as performances of the content-based recommendations.   \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Recommendation Based on Ensemble Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we combined all of the methods above as an ensemble learning to predict ratings of each restaurant for each user. As we described above, we averaged all of the predicted ratings of each item for each user that were calculated by user-based (using Euclidean distans and Pearson coefficient), item-based (using Euclidean distans and Pearson coefficient), and content-based recommendation systems, and we defined the averaged ratings as predicted ratings of the ensemble method.  \n",
    "  \n",
    "In general, ensemble learning improves performance because various errors of individual models average out, thus we considered this model as our final model to make a recommendation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a recommendation for a certain user\n",
    "First, we made a recommendation for a certain user. The following table displays the recommendation containing the predicted ratings and restaurant names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A recommendation for user Stefany\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg</th>\n",
       "      <th>business_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.242929</td>\n",
       "      <td>Little Miss BBQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.161305</td>\n",
       "      <td>Citizen Public House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.112718</td>\n",
       "      <td>Defalco's Italian Grocery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.063193</td>\n",
       "      <td>Cirque du Soleil - Mystère</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.040231</td>\n",
       "      <td>Mastro's Ocean Club</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.021675</td>\n",
       "      <td>Cirque du Soleil - Zumanity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.014777</td>\n",
       "      <td>Four Peaks Brewing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.004855</td>\n",
       "      <td>CUT by Wolfgang Puck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.984515</td>\n",
       "      <td>Le Reve - The Dream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.975148</td>\n",
       "      <td>Hwaro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        avg                  business_id\n",
       "0  4.242929              Little Miss BBQ\n",
       "1  4.161305         Citizen Public House\n",
       "2  4.112718    Defalco's Italian Grocery\n",
       "3  4.063193   Cirque du Soleil - Mystère\n",
       "4  4.040231          Mastro's Ocean Club\n",
       "5  4.021675  Cirque du Soleil - Zumanity\n",
       "6  4.014777           Four Peaks Brewing\n",
       "7  4.004855         CUT by Wolfgang Puck\n",
       "8  3.984515          Le Reve - The Dream\n",
       "9  3.975148                        Hwaro"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load each recommendation for the same user based on each method\n",
    "test_user = 'bLbSNkLggFnqwNNzzq-Ijw' # user_id to make a recommendation for \n",
    "user_rec_e = pd.DataFrame.from_dict(user_based_recommendations(data_dict, test_user, sim.euclidean_distance))\n",
    "user_rec_p = pd.DataFrame.from_dict(user_based_recommendations(data_dict, test_user, sim.pearson))\n",
    "item_rec_e = pd.DataFrame.from_dict(item_based_recommendations(data_dict, similarity_between_items(data_dict, similarity = sim.euclidean_distance), test_user))\n",
    "item_rec_p = pd.DataFrame.from_dict(item_based_recommendations(data_dict, similarity_between_items(data_dict, similarity = sim.pearson), test_user))\n",
    "user_rec_e.columns = ['stars_1', 'business_id']\n",
    "user_rec_p.columns = ['stars_2', 'business_id']\n",
    "item_rec_e.columns = ['stars_3', 'business_id']\n",
    "item_rec_p.columns = ['stars_4', 'business_id']\n",
    "\n",
    "# Join on \"business_id\"\n",
    "df12 = pd.merge(user_rec_e, user_rec_p, on='business_id', how='inner', suffixes=('_1', '_2'))\n",
    "df123 = pd.merge(df12, item_rec_e, on='business_id', how='inner', suffixes=('_12', '_3'))\n",
    "df1234 = pd.merge(df123, item_rec_p, on='business_id', how='inner', suffixes=('_123', '_4'))\n",
    "merged_rec = pd.merge(df1234, content_rec, on='business_id', how='inner', suffixes=('_1234', '_5'))\n",
    "\n",
    "merged_rec = merged_rec.dropna() # pick up only rows that have predicted ratings based on all methods\n",
    "merged_rec['avg'] = merged_rec[['stars_1','stars_2','stars_3','stars_4','predicted_stars']].mean(axis=1)    \n",
    "merged_rec = merged_rec.sort_values(by='avg', ascending=False) # sort by averaged ratings\n",
    "merged_rec['business_id'] = merged_rec['business_id'].apply(lambda s:item_name(s))\n",
    "merged_rec_rank = merged_rec[['avg', 'business_id']]\n",
    "merged_rec_rank = merged_rec_rank.reset_index(drop=True)\n",
    "print ('A recommendation for user %s' %user_name(test_user))\n",
    "merged_rec_rank.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing k-fold Cross-Validation\n",
    "Then, we performed *1*-fold cross-validation to test the performance of our ensemble method. Since this method requires much time to process, we performed *1*-fold cross-validation instead of 10-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_cv(data, k = 10, test_size = 0.1):\n",
    "    matrix_size = len(data['user_id'].unique()) * len(data['business_id'].unique())\n",
    "    rmse_values = []\n",
    "    mae_values = []\n",
    "    rmse2_values = []\n",
    "    mae2_values = []\n",
    "    cv_num = 0\n",
    "    ss = ShuffleSplit(n_splits=k, test_size=test_size, random_state=95885)\n",
    "\n",
    "    for train_index, test_index in ss.split(data):\n",
    "        # below is each validation process (in this for loop, we will iterate this process k times)\n",
    "        cv_num += 1\n",
    "        print('-- # of CV set: %s --' %cv_num)    \n",
    "        data_train, data_test= data.loc[train_index], data.loc[test_index] # split data into training and test\n",
    "        data_train.reset_index(drop=True, inplace=True) \n",
    "        data_test.reset_index(drop=True, inplace=True) \n",
    "        \n",
    "        ### User_based Recommendation using Euclidean Distance\n",
    "        ### User_based Recommendation using Pearson Coefficient\n",
    "        ### Item_based Recommendation using Euclidean Distance\n",
    "        ### Item_based Recommendation using Pearson Coefficient\n",
    "        # compute similarity, prediction (recommendation) based on training data\n",
    "        # create a dictionary for training data ({user: {(item: ratings), (item, ratings), ...}, ...})\n",
    "        train_dict = convert_dict(data_train) \n",
    "        \n",
    "        # create a dictionary for predicted data (recommendations for all users) \n",
    "        pred_dict_4 = {} # this will be {user: {item: pred_ratings (based on 4 metrics), ...}, ...}\n",
    "        print ('-- started user-based and item-based prediction --')\n",
    "        for user in train_dict.keys():\n",
    "            if user.find('_') == 0: # to avoid math domain error (user_id like '_something' will GET AN ERROR)\n",
    "                pass\n",
    "            else:\n",
    "                user_rec_e = pd.DataFrame.from_dict(user_based_recommendations(train_dict, user, sim.euclidean_distance))\n",
    "                user_rec_p = pd.DataFrame.from_dict(user_based_recommendations(train_dict, user, sim.pearson))\n",
    "                # Join on \"business_id\"\n",
    "                if len(user_rec_e) > 0 and len(user_rec_p) > 0:\n",
    "                    user_rec_e.columns = ['stars_1', 'business_id']\n",
    "                    user_rec_p.columns = ['stars_2', 'business_id']\n",
    "                    df12 = pd.merge(user_rec_e, user_rec_p, on='business_id', how='inner', suffixes=('_1', '_2'))\n",
    "                    item_rec_e = pd.DataFrame.from_dict(item_based_recommendations(train_dict, similarity_between_items(train_dict,similarity = sim.euclidean_distance),user))\n",
    "                    if len(item_rec_e) > 0:\n",
    "                        item_rec_e.columns = ['stars_3', 'business_id']\n",
    "                        df123 = pd.merge(df12, item_rec_e, on='business_id', how='inner', suffixes=('_12', '_3'))\n",
    "                        item_rec_p = pd.DataFrame.from_dict(item_based_recommendations(train_dict, similarity_between_items(train_dict,similarity = sim.pearson),user))\n",
    "                        if len(item_rec_p) >0: \n",
    "                            item_rec_p.columns = ['stars_4', 'business_id']\n",
    "                            merged_rec = pd.merge(df123, item_rec_p, on='business_id', how='inner', suffixes=('_123', '_4'))\n",
    "                            merged_rec = merged_rec.dropna() # pick up only rows that have predicted ratings based on all methods\n",
    "                            merged_rec['sum'] = merged_rec[['stars_1','stars_2','stars_3','stars_4']].sum(axis=1)    \n",
    "                            pred_rec = merged_rec[['business_id','sum']]\n",
    "                            #pred_rec.set_index('business_id')['sum']\n",
    "                            if len(pred_rec) > 0: # ignore users for whom no recommendation was made (based on all methods)\n",
    "                                user_pred_dict = {}\n",
    "                                for _, item in pred_rec.iterrows():\n",
    "                                    user_pred_dict.update({item['business_id']:item['sum']})\n",
    "                                pred_dict_4[user] = user_pred_dict # it is assumed that \"user\" is not in pred_dict_4\n",
    "        \n",
    "        ### Content-based Recommendation\n",
    "        ### make predictions (recommendation) based on training data by factorization\n",
    "        # User-item matrix\n",
    "        print ('-- started content-based prediction --')\n",
    "        user_ratings_mat_train = pd.pivot_table(data_train[['user_id', 'business_id', 'stars']], \n",
    "                                          index='user_id', columns='business_id',\n",
    "                                          aggfunc=np.max) # , fill_value=0)   \n",
    "        # Apply matrix factorization to find the latent features\n",
    "        # Now, we convert the dataframe \"matrix\" to a real 2D numpy matrix\n",
    "        mat = user_ratings_mat_train.as_matrix()\n",
    "        # This spolit matrix U: 100*a M: a*34 a: attributes of the movies\n",
    "        U, M = m.low_rank_matrix_factorization(mat, num_features=15, regularization_amount=0.1)\n",
    "        predicted_ratings_np = np.matmul(U, M)\n",
    "        # Convert the numpy matrix into a dataframe for easy viewing\n",
    "        predicted_ratings_df = pd.DataFrame(index     = user_ratings_mat_train.index,\n",
    "                                            columns   = user_ratings_mat_train.columns,\n",
    "                                            data      = predicted_ratings_np)\n",
    "        predicted_ratings_df[predicted_ratings_df>5] = 5 # restrict upper limit\n",
    "        predicted_ratings_df[predicted_ratings_df<1] = 1 # restrict lower limit\n",
    "        \n",
    "        ### Average predicted ratings based on ALL 5 metrics \n",
    "        pred_dict = {} \n",
    "        pred_dict_size = 0\n",
    "        for user in pred_dict_4.keys():\n",
    "            for item in pred_dict_4[user]:\n",
    "                # add the total predicted ratings based on 4 methods to the predicted ratings based on content-based recommendation\n",
    "                # and divide by 5; calculate average predicted ratings\n",
    "                sum_ratings = pred_dict_4[user][item]\n",
    "                #print(user, item, sum_ratings) # justfor debugging\n",
    "                content_ratings = predicted_ratings_df.loc[user]['stars'][item]\n",
    "                if content_ratings >= 1: # make sure predicted ratings based on content-based is not null\n",
    "                    pred = (sum_ratings + content_ratings) / 5\n",
    "                    if user not in pred_dict:\n",
    "                        pred_dict[user] = {item: pred}\n",
    "                        pred_dict_size += 1\n",
    "                    else:\n",
    "                        pred_dict[user].update({item: pred})\n",
    "                        pred_dict_size += 1\n",
    "                else: print('error:', user, item, content_ratings)\n",
    "                    \n",
    "        ### compute RMSE and MAE by comparing predicted ratings to test data\n",
    "        # Compare test data to predicted data and calculate RMSE and MAE\n",
    "        # (this process is the same as user-based or item-based recommendation k-fold CV)\n",
    "        print ('-- started validation --')      \n",
    "        test_dict = {}\n",
    "        test_dict_size = 0\n",
    "        for i in range(len(data_test)):\n",
    "            if data_test['user_id'].loc[i] not in test_dict:\n",
    "                test_dict[data_test['user_id'].loc[i]] = {data_test['business_id'].loc[i]:\n",
    "                                                          data_test['stars'].loc[i]}\n",
    "                test_dict_size += 1\n",
    "            else:\n",
    "                test_dict[data_test['user_id'].loc[i]].update({data_test['business_id'].loc[i]:\n",
    "                                                               data_test['stars'].loc[i]})\n",
    "                test_dict_size += 1\n",
    "        \n",
    "        sum_squared_error = 0\n",
    "        sum_absolute_error = 0\n",
    "        sum_squared_error2 = 0\n",
    "        sum_absolute_error2 = 0\n",
    "        count = 0\n",
    "        error_count = 0\n",
    "        \n",
    "        for user in test_dict.keys():\n",
    "            if user in pred_dict.keys():\n",
    "                for item in test_dict[user].keys():\n",
    "                    if item in pred_dict[user].keys():\n",
    "                        sum_squared_error += (pred_dict[user][item] - test_dict[user][item]) ** 2\n",
    "                        sum_absolute_error += abs(pred_dict[user][item] - test_dict[user][item])\n",
    "                        # Adjusted SE and AE (predicted ratings will be rounded because actual ratings are integer)\n",
    "                        sum_squared_error2 += (round(pred_dict[user][item],0) - test_dict[user][item]) ** 2\n",
    "                        sum_absolute_error2 += abs(round(pred_dict[user][item],0) - test_dict[user][item])\n",
    "                        if (round(pred_dict[user][item],0) - test_dict[user][item]) != 0:\n",
    "                            error_count += 1\n",
    "                        count += 1\n",
    "        \n",
    "        rmse = math.sqrt(sum_squared_error / count)\n",
    "        mae = sum_absolute_error / count\n",
    "        rmse2 = math.sqrt(sum_squared_error2 / count)\n",
    "        mae2 = sum_absolute_error2 / count\n",
    "        print(cv_num)\n",
    "        print('User-Item Matrix size', matrix_size)\n",
    "        print('Review data size predicted (recommendations made)', pred_dict_size)\n",
    "        print('Test data size used: ', count)\n",
    "        print('# of errors: ', error_count)\n",
    "        print('RMSE: ', rmse)\n",
    "        print('MAE: ', mae)\n",
    "        print('Adjusted RMSE: ', rmse2)\n",
    "        print('Adjusted MAE: ', mae2)\n",
    "        rmse_values.append(rmse)\n",
    "        mae_values.append(mae)\n",
    "        rmse2_values.append(rmse2)\n",
    "        mae2_values.append(mae2)\n",
    "    \n",
    "    # report the final results\n",
    "    mean_rmse = np.mean(rmse_values)\n",
    "    mean_mae = np.mean(mae_values)\n",
    "    mean_rmse2 = np.mean(rmse2_values)\n",
    "    mean_mae2 = np.mean(mae2_values)\n",
    "    print ('Overall performance')\n",
    "    print ('Mean RMSE: %s' % round(mean_rmse,4))\n",
    "    print ('Mean MAE: %s' % round(mean_mae,4))\n",
    "    print ('Mean Adjusted RMSE: %s' % round(mean_rmse2,4))\n",
    "    print ('Mean Adjusted MAE: %s' % round(mean_mae2,4))\n",
    "    return mean_rmse, mean_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- # of CV set: 1 --\n",
      "# of users in the data 1040\n",
      "# of reveiws in the data: 6619\n",
      "-- started user-based and item-based prediction --\n",
      "-- started content-based prediction --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hika1\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:67: FutureWarning:\n",
      "\n",
      "Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 257.849864\n",
      "         Iterations: 3000\n",
      "         Function evaluations: 4455\n",
      "         Gradient evaluations: 4455\n",
      "-- started validation --\n",
      "1\n",
      "User-Item Matrix size 319504\n",
      "Review data size predicted (recommendations made) 64951\n",
      "Test data size used:  449\n",
      "# of errors:  261\n",
      "RMSE:  0.908037231925645\n",
      "MAE:  0.7276548600958623\n",
      "Adjusted RMSE:  0.9367526716955391\n",
      "Adjusted MAE:  0.6770601336302895\n",
      "Overall performance\n",
      "Mean RMSE: 0.908\n",
      "Mean MAE: 0.7277\n",
      "Mean Adjusted RMSE: 0.9368\n",
      "Mean Adjusted MAE: 0.6771\n"
     ]
    }
   ],
   "source": [
    "# \"E\"\n",
    "# Note: this takes more than 30 minutes.\n",
    "ensemble_1_r, ensemble_1_a = ensemble_cv(data_e, k =1, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- # of CV set: 1 --\n",
      "# of users in the data 1160\n",
      "# of reveiws in the data: 13239\n",
      "-- started user-based and item-based prediction --\n",
      "-- started content-based prediction --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hika1\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:67: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 413.959488\n",
      "         Iterations: 3000\n",
      "         Function evaluations: 4493\n",
      "         Gradient evaluations: 4493\n",
      "-- started validation --\n",
      "1\n",
      "User-Item Matrix size 357200\n",
      "Review data size predicted (recommendations made) 208129\n",
      "Test data size used:  1357\n",
      "# of errors:  780\n",
      "RMSE:  0.905788160738991\n",
      "MAE:  0.706885805261568\n",
      "Adjusted RMSE:  0.9609164134936213\n",
      "Adjusted MAE:  0.681650700073692\n",
      "Overall performance\n",
      "Mean RMSE: 0.9058\n",
      "Mean MAE: 0.7069\n",
      "Mean Adjusted RMSE: 0.9609\n",
      "Mean Adjusted MAE: 0.6817\n"
     ]
    }
   ],
   "source": [
    "# \"E + Delta E\"\n",
    "# Note: this takes more than 30-60 minutes\n",
    "ensemble_2_r, ensemble_2_a = ensemble_cv(data, k=1, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the performance of content-based recommendations (when we use the entire data (\"E + Delta E\") is approximately 0.9 for RMSE and 0.7 for MAE. Adjusted RMSE and MAE are RMSE and MAE when we round the predicted ratings. Similar to user-based recommendations, comparing the rounded predicted ratings and actual ratings, we found that approximately a half of predictions matched the actual ratings in the test data. Interestingly, the number of erros is slightly smaller than user-basd recommendations, which performs the best of all the three methods. Therefore, we can confirm the efficacy of ensemble learning here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='brightpink'>Performance Evaluation</font> <a name=\"performance\"></a>\n",
    "We summarized the performances of our recommendation systems as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendation Comparison\n",
    "First, we merged the recommendations for a certain user made based on user-based (using Pearson coefficient as a similarity calculation method), item-based (using Pearson coefficient as a similarity calculation method), content-based, and ensemble-based recommendation systems so that we can compare how close or different each recommendation is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user Stefany\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars_u</th>\n",
       "      <th>user_based</th>\n",
       "      <th>stars_i</th>\n",
       "      <th>item_based</th>\n",
       "      <th>stars_c</th>\n",
       "      <th>content_based</th>\n",
       "      <th>stars_e</th>\n",
       "      <th>ensemble</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0000</td>\n",
       "      <td>Meat &amp; Potatoes</td>\n",
       "      <td>4.1780</td>\n",
       "      <td>Amélie's French Bakery &amp; Café</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>Firefly</td>\n",
       "      <td>4.2429</td>\n",
       "      <td>Little Miss BBQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9459</td>\n",
       "      <td>Hwaro</td>\n",
       "      <td>3.9911</td>\n",
       "      <td>Arizona Wilderness Brewing</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>CUT by Wolfgang Puck</td>\n",
       "      <td>4.1613</td>\n",
       "      <td>Citizen Public House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9142</td>\n",
       "      <td>Little Miss BBQ</td>\n",
       "      <td>3.9663</td>\n",
       "      <td>Cabo Fish Taco</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>Cirque du Soleil - Zumanity</td>\n",
       "      <td>4.1127</td>\n",
       "      <td>Defalco's Italian Grocery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.8669</td>\n",
       "      <td>Backyard Taco</td>\n",
       "      <td>3.9023</td>\n",
       "      <td>OHSO Brewery- Arcadia</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>Cirque du Soleil - Mystère</td>\n",
       "      <td>4.0632</td>\n",
       "      <td>Cirque du Soleil - Mystère</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.8598</td>\n",
       "      <td>Gordon Ramsay Hell's Kitchen</td>\n",
       "      <td>3.8589</td>\n",
       "      <td>Postino Central</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>Excalibur Hotel</td>\n",
       "      <td>4.0402</td>\n",
       "      <td>Mastro's Ocean Club</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.8220</td>\n",
       "      <td>Bobby Q</td>\n",
       "      <td>3.8545</td>\n",
       "      <td>Paradise Valley Burger Company</td>\n",
       "      <td>4.7762</td>\n",
       "      <td>Defalco's Italian Grocery</td>\n",
       "      <td>4.0217</td>\n",
       "      <td>Cirque du Soleil - Zumanity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.7803</td>\n",
       "      <td>Cherryblossom Noodle Cafe</td>\n",
       "      <td>3.7703</td>\n",
       "      <td>Postino Arcadia</td>\n",
       "      <td>4.7484</td>\n",
       "      <td>Eggslut</td>\n",
       "      <td>4.0148</td>\n",
       "      <td>Four Peaks Brewing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.7796</td>\n",
       "      <td>Fogo de Chão Brazilian Steakhouse</td>\n",
       "      <td>3.7558</td>\n",
       "      <td>Citizen Public House</td>\n",
       "      <td>4.7431</td>\n",
       "      <td>Mastro's Ocean Club</td>\n",
       "      <td>4.0049</td>\n",
       "      <td>CUT by Wolfgang Puck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.7693</td>\n",
       "      <td>Tacos El Gordo</td>\n",
       "      <td>3.7555</td>\n",
       "      <td>Taco Guild</td>\n",
       "      <td>4.7344</td>\n",
       "      <td>Pizzeria Bianco</td>\n",
       "      <td>3.9845</td>\n",
       "      <td>Le Reve - The Dream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.7382</td>\n",
       "      <td>Citizen Public House</td>\n",
       "      <td>3.7516</td>\n",
       "      <td>Pai Northern Thai Kitchen</td>\n",
       "      <td>4.6488</td>\n",
       "      <td>M Resort Spa Casino</td>\n",
       "      <td>3.9751</td>\n",
       "      <td>Hwaro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.6824</td>\n",
       "      <td>Sage</td>\n",
       "      <td>3.7444</td>\n",
       "      <td>Harumi Sushi</td>\n",
       "      <td>4.5143</td>\n",
       "      <td>Four Peaks Brewing</td>\n",
       "      <td>3.9735</td>\n",
       "      <td>SumoMaya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.6442</td>\n",
       "      <td>KINKA IZAKAYA ORIGINAL</td>\n",
       "      <td>3.7251</td>\n",
       "      <td>KINKA IZAKAYA ORIGINAL</td>\n",
       "      <td>4.5074</td>\n",
       "      <td>Sushi Mon</td>\n",
       "      <td>3.9631</td>\n",
       "      <td>Sushi Mon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.5984</td>\n",
       "      <td>Barrio Café</td>\n",
       "      <td>3.7192</td>\n",
       "      <td>Lemongrass</td>\n",
       "      <td>4.4364</td>\n",
       "      <td>Gaucho Parrilla Argentina</td>\n",
       "      <td>3.9569</td>\n",
       "      <td>Firefly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.5745</td>\n",
       "      <td>SumoMaya</td>\n",
       "      <td>3.7121</td>\n",
       "      <td>Chayo Mexican Kitchen + Tequila Bar</td>\n",
       "      <td>4.4063</td>\n",
       "      <td>Le Reve - The Dream</td>\n",
       "      <td>3.9288</td>\n",
       "      <td>Meat &amp; Potatoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.5195</td>\n",
       "      <td>Khao San Road</td>\n",
       "      <td>3.7094</td>\n",
       "      <td>Defalco's Italian Grocery</td>\n",
       "      <td>4.3740</td>\n",
       "      <td>Seven Lives Tacos Y Mariscos</td>\n",
       "      <td>3.9262</td>\n",
       "      <td>Top of the World</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      stars_u                         user_based  stars_i  \\\n",
       "rank                                                        \n",
       "1      5.0000                    Meat & Potatoes   4.1780   \n",
       "2      4.9459                              Hwaro   3.9911   \n",
       "3      4.9142                    Little Miss BBQ   3.9663   \n",
       "4      4.8669                      Backyard Taco   3.9023   \n",
       "5      4.8598       Gordon Ramsay Hell's Kitchen   3.8589   \n",
       "6      4.8220                            Bobby Q   3.8545   \n",
       "7      4.7803          Cherryblossom Noodle Cafe   3.7703   \n",
       "8      4.7796  Fogo de Chão Brazilian Steakhouse   3.7558   \n",
       "9      4.7693                     Tacos El Gordo   3.7555   \n",
       "10     4.7382               Citizen Public House   3.7516   \n",
       "11     4.6824                               Sage   3.7444   \n",
       "12     4.6442             KINKA IZAKAYA ORIGINAL   3.7251   \n",
       "13     4.5984                        Barrio Café   3.7192   \n",
       "14     4.5745                           SumoMaya   3.7121   \n",
       "15     4.5195                      Khao San Road   3.7094   \n",
       "\n",
       "                               item_based  stars_c  \\\n",
       "rank                                                 \n",
       "1           Amélie's French Bakery & Café   5.0000   \n",
       "2              Arizona Wilderness Brewing   5.0000   \n",
       "3                          Cabo Fish Taco   5.0000   \n",
       "4                   OHSO Brewery- Arcadia   5.0000   \n",
       "5                         Postino Central   5.0000   \n",
       "6          Paradise Valley Burger Company   4.7762   \n",
       "7                         Postino Arcadia   4.7484   \n",
       "8                    Citizen Public House   4.7431   \n",
       "9                              Taco Guild   4.7344   \n",
       "10              Pai Northern Thai Kitchen   4.6488   \n",
       "11                           Harumi Sushi   4.5143   \n",
       "12                 KINKA IZAKAYA ORIGINAL   4.5074   \n",
       "13                             Lemongrass   4.4364   \n",
       "14    Chayo Mexican Kitchen + Tequila Bar   4.4063   \n",
       "15              Defalco's Italian Grocery   4.3740   \n",
       "\n",
       "                     content_based  stars_e                     ensemble  \n",
       "rank                                                                      \n",
       "1                          Firefly   4.2429              Little Miss BBQ  \n",
       "2             CUT by Wolfgang Puck   4.1613         Citizen Public House  \n",
       "3      Cirque du Soleil - Zumanity   4.1127    Defalco's Italian Grocery  \n",
       "4       Cirque du Soleil - Mystère   4.0632   Cirque du Soleil - Mystère  \n",
       "5                  Excalibur Hotel   4.0402          Mastro's Ocean Club  \n",
       "6        Defalco's Italian Grocery   4.0217  Cirque du Soleil - Zumanity  \n",
       "7                          Eggslut   4.0148           Four Peaks Brewing  \n",
       "8              Mastro's Ocean Club   4.0049         CUT by Wolfgang Puck  \n",
       "9                  Pizzeria Bianco   3.9845          Le Reve - The Dream  \n",
       "10             M Resort Spa Casino   3.9751                        Hwaro  \n",
       "11              Four Peaks Brewing   3.9735                     SumoMaya  \n",
       "12                       Sushi Mon   3.9631                    Sushi Mon  \n",
       "13       Gaucho Parrilla Argentina   3.9569                      Firefly  \n",
       "14             Le Reve - The Dream   3.9288              Meat & Potatoes  \n",
       "15    Seven Lives Tacos Y Mariscos   3.9262             Top of the World  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item = pd.concat([user_rec, item_rec], axis=1)\n",
    "user_item_content = pd.concat([user_item, content_rec], axis=1)\n",
    "comparison = pd.concat([user_item_content, merged_rec_rank], axis=1)\n",
    "comparison.columns = ['stars_u','user_based','stars_i','item_based','stars_c','content_based','stars_e','ensemble']\n",
    "\n",
    "# Round predicted ratings\n",
    "comparison['stars_u'] = comparison['stars_u'].apply(lambda f:round(f,4))\n",
    "comparison['stars_i'] = comparison['stars_i'].apply(lambda f:round(f,4))\n",
    "comparison['stars_c'] = comparison['stars_c'].apply(lambda f:round(f,4))\n",
    "comparison['stars_e'] = comparison['stars_e'].apply(lambda f:round(f,4))\n",
    "\n",
    "# Convert business_id into restaurant name\n",
    "comparison['user_based'] = comparison['user_based'].apply(lambda s:item_name(s))\n",
    "comparison['item_based'] = comparison['item_based'][-comparison['item_based'].isnull()].apply(lambda s:item_name(s)) # because this conttains 2 null values\n",
    "comparison['content_based'] = comparison['content_based'].apply(lambda s:item_name(s))\n",
    "\n",
    "# Index ranks\n",
    "comparison['rank'] = [i+1 for i in range(len(comparison))]\n",
    "comparison.index = comparison['rank']\n",
    "comparison = comparison.drop('rank', axis=1)\n",
    "comparison.to_csv('comparison.csv') # if you want to save this table\n",
    "\n",
    "# Display Top N\n",
    "N = 15\n",
    "print ('Recommendations for user %s' %user_name(test_user))\n",
    "comparison.head(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table displays top 15 recommendations for use Stefany based on each method. It appears that restaurants recommended largely differ within the top 15 rankings among the three methods. A few restaurants such as KINKA IZAKAYA ORIGINAL and Citizen Public House can be seen in different rankings.  \n",
    "However, the recommendation made by the ensemble method includes many restaurants that are ranked in other methods. (Because of its nature of ensembling, this might be reasonable.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>RMSE(E)</th>\n",
       "      <th>RMSE(E+ΔE)</th>\n",
       "      <th>MAE(E)</th>\n",
       "      <th>MAE(E+ΔE)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recommendation</th>\n",
       "      <th>Similarity_Metrics</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">User-based</th>\n",
       "      <th>Euclidean Distance</th>\n",
       "      <td>0.9360</td>\n",
       "      <td>0.8927</td>\n",
       "      <td>0.7287</td>\n",
       "      <td>0.6941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pearson Coefficient</th>\n",
       "      <td>1.0274</td>\n",
       "      <td>0.9235</td>\n",
       "      <td>0.7843</td>\n",
       "      <td>0.7187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Item-based</th>\n",
       "      <th>Euclidean Distance</th>\n",
       "      <td>0.9949</td>\n",
       "      <td>0.9756</td>\n",
       "      <td>0.7761</td>\n",
       "      <td>0.7590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pearson Coefficient</th>\n",
       "      <td>1.0785</td>\n",
       "      <td>1.0019</td>\n",
       "      <td>0.8271</td>\n",
       "      <td>0.7769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Content-based</th>\n",
       "      <th></th>\n",
       "      <td>1.2620</td>\n",
       "      <td>1.4431</td>\n",
       "      <td>1.0033</td>\n",
       "      <td>1.1338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    RMSE(E)  RMSE(E+ΔE)  MAE(E)  MAE(E+ΔE)\n",
       "Recommendation Similarity_Metrics                                         \n",
       "User-based     Euclidean Distance    0.9360      0.8927  0.7287     0.6941\n",
       "               Pearson Coefficient   1.0274      0.9235  0.7843     0.7187\n",
       "Item-based     Euclidean Distance    0.9949      0.9756  0.7761     0.7590\n",
       "               Pearson Coefficient   1.0785      1.0019  0.8271     0.7769\n",
       "Content-based                        1.2620      1.4431  1.0033     1.1338"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_mat = pd.DataFrame({'Recommendation': ['User-based', 'User-based', 'Item-based', 'Item-based', 'Content-based'],\n",
    "                                'Similarity_Metrics': ['Euclidean Distance', 'Pearson Coefficient', 'Euclidean Distance', 'Pearson Coefficient', ''],\n",
    "                                'RMSE(E)': [user_based_e1_r, user_based_p1_r, item_based_e1_r, item_based_p1_r, content_based_f1_r],\n",
    "                                'RMSE(E+ΔE)': [user_based_e2_r, user_based_p2_r, item_based_e2_r, item_based_p2_r, content_based_f2_r],\n",
    "                                'MAE(E)': [user_based_e1_a, user_based_p1_a, item_based_e1_a, item_based_p1_a, content_based_f1_a],\n",
    "                                'MAE(E+ΔE)': [user_based_e2_a, user_based_p2_a, item_based_e2_a, item_based_p2_a, content_based_f2_a],\n",
    "                                })\n",
    "\n",
    "performance_mat[['RMSE(E)', 'RMSE(E+ΔE)', 'MAE(E)', 'MAE(E+ΔE)']] = performance_mat[['RMSE(E)', 'RMSE(E+ΔE)', 'MAE(E)', 'MAE(E+ΔE)']].apply(lambda f:round(f,4))\n",
    "performance_mat.to_csv('performance_mat.csv') # if you want to save this table\n",
    "performance_mat = performance_mat.set_index(['Recommendation', 'Similarity_Metrics']) \n",
    "performance_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE and MAE here are normal RMSE and MAE (i.e. they are not adjusted RMSE and MAE as mentioned above). RMSE and MAE of a content-based recommendation are based on regulalized predicted ratings as described above. \n",
    "  \n",
    "Overall, user-based recommendation systems performed better than item-based recommendation systems and content-based recommendation system because both of RMSE and MAE are relatively lower, which means that the magnitude of erros in user-based recommendation systems is lower than that in other systems.  \n",
    "  \n",
    "It was expected that the performances of user-based recommendation and item-based recommendation are similar, but they are slightly different (the performance of user-based recommendation is slightly better). We think that this is because that the number of restaurants (items) are much fewer than the number of users. When we calculate weighted average ratings (i.e. predicted ratings) for each user, we generally sum up the of weighted ratings of similar users/items (a product of ratings of similar users/items and similarity) and divide it by the number of similar users/items (user-based/item-based recommendation, respectively). In general, larger and larger the number of samples is, more and more plausible the average would be (because variance is smaller). In that sense, the weighted average ratings based on user-based recommendation is more plausible than that based on item-based recommendation. That is why the overall performance of user-based recommendation was better.  \n",
    "  \n",
    "The reason why content-based recommendation's performance was not better than other methods is considered that content-based recommendation can predict all ratings for each user-item combination by its nature of using factorization while user-based and item-based recommendation system ignore non-similar users/items and users/items with few actual ratings when predicting ratings. This means that content-based recommendation contains non-reliable predicted ratings (for such users) and thus the magnitude of errors in content-based recommendation could be larger because of their larger variance. Another reason might be the number of latent features we set. We set it as 15, but it might not have been sufficient to the size of a 1500 * 300 matrix. We could have tuned this hyperparameter, but since matrix factorization requires much time and machine power, we actually could not try some values of this hyperparameters.  \n",
    "  \n",
    "From the perspective of the difference in performances of between RMSE and MAE, the values of RMSE are larger than those of MAE. This result is considered reasonable because RMSE is calculated by dividing a square root of a sum of a errors to the power of 2 by \"square root of the number of samples\" while MAE is calculated by dividing a sum of absolute errors by \"the number of samples.\"  \n",
    "\n",
    "Regarding user-based and item-based recommendations, using Euclidean distance as a similarity calculation method performed better than using Pearson coefficient. We believe that this is mostly because more data is used to predict ratings when we utilize Euclidean distance. As the code above indicates, when we calculated similarity, we explicitly removed user (or item) pairs that have negative coefficients (because they are not similar at all), which resulted in fewer number of samples to be used for prediction.     \n",
    "\n",
    "In terms of the difference in performances of between using data \"E\" and using data \"E + delta E\", we clearly see that the performances when using \"E + delta E\" are better than those when using \"E\", which means that learning has happend. \n",
    "    \n",
    "However, content-based recommendation is only an exception. For this system, increasing data adversely reduced the performance. It is unclear why it happened, but our hypothesis is that using more data leads to increasing the magnitude of errors because it can predict ratings for even users that do not have similar users or for items that similar users have not rated for. Another hypothesis is that the number of latent features necessary to predict in the larger dataset as accurately as the smaller dataset might be much larger. For example, it may be possible that the number of latent features necessary in the smaller data is 15, while that in the larger data is 60. (From that perspective, if this hypothesis is true, content-based recommendation would not be suitable to for large dataset.) We set both the numbers of latent features in those datasets as 15 and could have tuned this hyperparameter, but we could not try some values of this hyperparameters for the same reason mentioned above. These hypotheses are similar to the reason why content-based recommendation system performed worse than other recommendation systems.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>RMSE(E)</th>\n",
       "      <th>RMSE(E+ΔE)</th>\n",
       "      <th>MAE(E)</th>\n",
       "      <th>MAE(E+ΔE)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recommendation</th>\n",
       "      <th>Similarity_Metrics</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">User-based</th>\n",
       "      <th>Euclidean Distance</th>\n",
       "      <td>0.9360</td>\n",
       "      <td>0.8927</td>\n",
       "      <td>0.7287</td>\n",
       "      <td>0.6941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pearson Coefficient</th>\n",
       "      <td>1.0274</td>\n",
       "      <td>0.9235</td>\n",
       "      <td>0.7843</td>\n",
       "      <td>0.7187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Item-based</th>\n",
       "      <th>Euclidean Distance</th>\n",
       "      <td>0.9949</td>\n",
       "      <td>0.9756</td>\n",
       "      <td>0.7761</td>\n",
       "      <td>0.7590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pearson Coefficient</th>\n",
       "      <td>1.0785</td>\n",
       "      <td>1.0019</td>\n",
       "      <td>0.8271</td>\n",
       "      <td>0.7769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Content-based</th>\n",
       "      <th></th>\n",
       "      <td>1.2620</td>\n",
       "      <td>1.4431</td>\n",
       "      <td>1.0033</td>\n",
       "      <td>1.1338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble</th>\n",
       "      <th></th>\n",
       "      <td>0.9080</td>\n",
       "      <td>0.9058</td>\n",
       "      <td>0.7277</td>\n",
       "      <td>0.7069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    RMSE(E)  RMSE(E+ΔE)  MAE(E)  MAE(E+ΔE)\n",
       "Recommendation Similarity_Metrics                                         \n",
       "User-based     Euclidean Distance    0.9360      0.8927  0.7287     0.6941\n",
       "               Pearson Coefficient   1.0274      0.9235  0.7843     0.7187\n",
       "Item-based     Euclidean Distance    0.9949      0.9756  0.7761     0.7590\n",
       "               Pearson Coefficient   1.0785      1.0019  0.8271     0.7769\n",
       "Content-based                        1.2620      1.4431  1.0033     1.1338\n",
       "Ensemble                             0.9080      0.9058  0.7277     0.7069"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_mat2 = pd.DataFrame({'Recommendation': ['User-based', 'User-based', 'Item-based', 'Item-based', 'Content-based', 'Ensemble'],\n",
    "                                 'Similarity_Metrics': ['Euclidean Distance', 'Pearson Coefficient', 'Euclidean Distance', 'Pearson Coefficient', '', ''],\n",
    "                                 'RMSE(E)': [user_based_e1_r, user_based_p1_r, item_based_e1_r, item_based_p1_r, content_based_f1_r, ensemble_1_r],\n",
    "                                 'RMSE(E+ΔE)': [user_based_e2_r, user_based_p2_r, item_based_e2_r, item_based_p2_r, content_based_f2_r, ensemble_2_r],\n",
    "                                 'MAE(E)': [user_based_e1_a, user_based_p1_a, item_based_e1_a, item_based_p1_a, content_based_f1_a, ensemble_1_a],\n",
    "                                 'MAE(E+ΔE)': [user_based_e2_a, user_based_p2_a, item_based_e2_a, item_based_p2_a, content_based_f2_a, ensemble_2_a],\n",
    "                                 })\n",
    "\n",
    "performance_mat2[['RMSE(E)', 'RMSE(E+ΔE)', 'MAE(E)', 'MAE(E+ΔE)']] = performance_mat2[['RMSE(E)', 'RMSE(E+ΔE)', 'MAE(E)', 'MAE(E+ΔE)']].apply(lambda f:round(f,4))\n",
    "performance_mat2.to_csv('performance_mat2.csv') # if you want to save this table\n",
    "performance_mat2 = performance_mat2.set_index(['Recommendation', 'Similarity_Metrics']) \n",
    "performance_mat2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we compared the performance of the ensemble method to performances of other metrics. As we expected, overall, our final model, the ensemble method performed better than any other method.  \n",
    "  \n",
    "Using the entire data, RMSE is approximately 0.9, and MAE is approximately 0.7. This implies that the average magnitude of error is approximately 0.7. The difference between RMSE and MAE is as discussed above. As far as we researched, RMSE is generally around 1.0 to 1.2 in the prior studies using similar Yelp dataset. Therefore, we can say that we successfully developed a better model of recommendation system on Yelp. (However, since the size of data used to make predictions in the prior studies was larger than ours (such as 180,000 reviews, compared to 14,700 reviews in our analysis), there is a possibility that this argument might not be perfectly fair.)  \n",
    "    \n",
    "Also We can conclude here that learning has happened because if we use more data, the performances of the ensemble model improved.  \n",
    "  \n",
    "Besides, one of the greatest characteristics of the ensemble models is that the performance when we used less data (only “E”) was drastically improved, which indicates this model does not require much data to predict as accurately as other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='brightpink'>Contributions and Future Tasks</font> <a name=\"cont\"></a>\n",
    "Our work can contribute the problem mentioned at the beginning of the report in the following ways:\n",
    "- Utilizing and improving this recommendation system, Yelp can offer recommendation service to their customers, which will enhance customers' satisfaction and Yelp's value in turn. As Netflix's Chief Product Officer Neil Hunt states, “the combined effect of personalization and recommendations save\" Yelp large amount of money by attracting more users to Yelp and retain current users amnd encouraging more reviews and ratings from users. \n",
    "- Since Yelp makes revenue mostly from advertisement, letting more customers access the website will increase opportunities to click the advertisement on the site, which will result in Yelp's revenue growth. \n",
    "- Our ensemble model performs better than other prior models that have been made  so far, which indicates that Yelp can offer more effective/reliable recommendation system. In other words, Yelp can make recommendations for users which they will be likely to be satisfied with.  \n",
    "- As a side effect, restaurants can also benefit from this system/improvement for free (since they do not pay to Yelp). They would become more likely to acquire potential loyal customers by the personalized recommendation system on Yelp. According to Alessandro Vitale's article, on Netflix, \"75% of what people watch is from some sort of recommendation.\" This fact implies great potential for restaurants on Yelp.\n",
    "  \n",
    "To achive our aim to help Yelp enhance their value, we and Yelp need to do the following challenges in the future:\n",
    "- From the business perspective, Yelp should make efforts to collect an influx of data on users preferences and personalities as consumers data to provide users personalized recommendations to restaurants and other services. (Over the years, it seems that Yelp has collected this data, though.) This is because one of the reason why Yelp has not provided recommendation system so far is considered “sparsity.” For Yelp, it may be extremely difficult to predict ratings for light users (and unpopular businesses). Our algorithm should help this issue (by improving in the future), but Yelp also needs to make efforts to solve this issue. \n",
    "- From the technical perspective, it is necessary to use machines that can handle much larger data so that we can include users/items with less than 1,000 review counts as well as tune hyperparameters smoothly.\n",
    "- Also, it is necessary to tune wights for averaging predicted ratings based on each method regarding the ensemble method; in this project, we just evenly weighted the predicted ratings. Similarly, we could tune the hyperparameter of the number of latent features of the content-based recommendation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sumedh Sawant, “Yelp Food Recommendation System”, http://cs229.stanford.edu/proj2013/SawantPai-YelpFoodRecommendationSystem.pdf  \n",
    "- Yinuo Yao, Fangmingyu Yang, and Xin Niu, “CS229 Project Final Report A Personalized Recommendation System for Yelp Users”, http://cs229.stanford.edu/proj2016/report/YaoNiuYang-A%20Personalized%20Recommendation%20System%20for%20Yelp%20Users-report.pdf \n",
    "- “Yelp Dataset Challenge”, Yelp, https://www.yelp.com/dataset_challenge   \n",
    "- “Yelp Dataset JSON”, Yelp, https://www.yelp.com/dataset/documentation/main   \n",
    "- Panagiotis Karagiannis, Juraj Juraska, Noujan Pashanasangi, and Konstantinos Zampetakis, “Restaurant Recommender System for Yelp”, https://pdfs.semanticscholar.org/60f1/6d5cbed28a1df409d4122aeea7ea20d4dd02.pdf   - “A Preference-Based Restaurant Recommendation System for Individuals and Groups. Team Size: 3”, https://www.cs.cornell.edu/~rahmtin/Files/YelpClassProject.pdf  \n",
    "- \"MAE and RMSE — Which Metric is Better?\", https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d\n",
    "- Alessandro Vitale, \"The importance of filtering in Recommender Systems\", https://medium.com/@alevitale/the-importance-of-filtering-in-recommender-systems-8040c0e16516\n",
    "- Naomi Carrillo et al., \"Recommender Systems Designed for Yelp.com\", https://www.math.uci.edu/icamp/summer/research/student_research/recommender_systems_slides.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
